const express = require('express');
const cors = require('cors');
const multer = require('multer');
const { GoogleGenAI, Type } = require('@google/genai');
const OllamaService = require('./ollamaService');
const { getFinancialSummary, plaidClient } = require('./plaidClient');
const { generateChart } = require('./chartTools');
const { textToSpeech, streamTextToSpeech, cleanTextForSpeech } = require('./cartesiaService');
const DailyService = require('./dailyService');
const GeminiLiveStreamingService = require('./geminiLiveStreamingService');
const convexService = require('./convexService');
const OpenAI = require('openai');
const http = require('http');
const WebSocket = require('ws');
require('dotenv').config();

// Test user flag - set to false for production
const USE_TEST_USER = process.env.USE_TEST_USER !== 'false';
const TEST_USER_ID = 'test_user';

console.log(`üß™ Test user mode: ${USE_TEST_USER ? 'ENABLED' : 'DISABLED'}`);

// Convert plain text to HTML formatting
function convertToHTML(text) {
  if (!text) return '';
  
  // If already has HTML tags, return as-is
  if (text.includes('<h3>') || text.includes('<p>')) {
    return text;
  }
  
  // Split into paragraphs and convert
  const paragraphs = text.split('\n\n').filter(p => p.trim());
  let html = '';
  
  for (let i = 0; i < paragraphs.length; i++) {
    const para = paragraphs[i].trim();
    if (!para) continue;
    
    // First paragraph becomes header if it's short and doesn't have special formatting
    if (i === 0 && para.length < 60 && !para.includes('*') && !para.includes('-')) {
      html += `<h3>${para}</h3>`;
    } else {
      // Convert markdown-style formatting
      let htmlPara = para
        .replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>') // Bold
        .replace(/\*(.*?)\*/g, '<em>$1</em>') // Italic
        .replace(/\n/g, '<br>'); // Line breaks
      
      // Handle bullet points
      if (htmlPara.includes('‚Ä¢') || htmlPara.includes('*   ')) {
        const lines = htmlPara.split('\n');
        const listItems = lines
          .filter(line => line.trim().startsWith('‚Ä¢') || line.trim().startsWith('*'))
          .map(line => `<li>${line.replace(/^[‚Ä¢*]\s*/, '').trim()}</li>`)
          .join('');
        
        if (listItems) {
          html += `<ul>${listItems}</ul>`;
        } else {
          html += `<p>${htmlPara}</p>`;
        }
      } else {
        html += `<p>${htmlPara}</p>`;
      }
    }
  }
  
  return html || `<p>${text}</p>`;
}

// Transaction categorization handler
async function handleTransactionCategorization(message, botMessage, res) {
  console.log('üîß DEBUG: Checking for transaction categorization...');
  
  const shouldCategorize = message.toLowerCase().includes('categor') || 
                          message.toLowerCase().includes('tx_') ||
                          message.toLowerCase().includes('transaction') ||
                          message.toLowerCase().includes('uncategorized') ||
                          message.toLowerCase().includes('budget');
  
  console.log('üîß DEBUG: Should categorize:', shouldCategorize);
  
  if (shouldCategorize) {
    console.log('üîß DEBUG: Checking for uncategorized transactions...');
    
    try {
      const userId = USE_TEST_USER ? TEST_USER_ID : 'default_user';
      
      // Get uncategorized transactions from Convex
      const uncategorizedTxs = await convexService.getUncategorizedTransactions(userId);
      console.log(`üîß DEBUG: Found ${uncategorizedTxs.length} uncategorized transactions`);
      
      if (uncategorizedTxs.length > 0) {
        // Show uncategorized transactions for user to categorize
        botMessage += `\n\nüí° I found ${uncategorizedTxs.length} uncategorized transaction${uncategorizedTxs.length > 1 ? 's' : ''} that need${uncategorizedTxs.length === 1 ? 's' : ''} your attention:\n\n`;
        
        const transactionsToShow = uncategorizedTxs.slice(0, 5); // Show first 5
        
        for (const tx of transactionsToShow) {
          const amount = Math.abs(tx.amount || 0);
          const merchant = tx.enrichedMerchantName || tx.merchantName || tx.description || 'Unknown';
          const date = new Date(tx.date).toLocaleDateString();
          
          // AI-powered category suggestion based on merchant/description
          let suggestion = 'wild_cards';
          let confidence = 0.6;
          
          const merchantLower = merchant.toLowerCase();
          const descLower = (tx.description || '').toLowerCase();
          
          if (merchantLower.includes('starbucks') || merchantLower.includes('coffee') || 
              merchantLower.includes('netflix') || merchantLower.includes('spotify') ||
              descLower.includes('entertainment') || descLower.includes('restaurant')) {
            suggestion = 'delights';
            confidence = 0.8;
          } else if (merchantLower.includes('grocery') || merchantLower.includes('gas') ||
                    merchantLower.includes('rent') || merchantLower.includes('mortgage') ||
                    merchantLower.includes('utility') || descLower.includes('insurance')) {
            suggestion = 'foundations';
            confidence = 0.9;
          } else if (merchantLower.includes('investment') || merchantLower.includes('saving') ||
                    descLower.includes('transfer') || descLower.includes('deposit')) {
            suggestion = 'nest_egg';
            confidence = 0.7;
          }
          
          botMessage += `**${tx.txId}** - ${merchant}\n`;
          botMessage += `   $${amount.toFixed(2)} on ${date}\n`;
          botMessage += `   ü§ñ Suggested: **${suggestion}** (${Math.round(confidence * 100)}% confidence)\n\n`;
          
          // Auto-categorize high confidence suggestions
          if (confidence >= 0.8) {
            try {
              await convexService.suggestCategory(tx.txId, suggestion, confidence);
              console.log(`üîß DEBUG: Auto-categorized ${tx.txId} as ${suggestion}`);
            } catch (error) {
              console.error(`üîß DEBUG: Error auto-categorizing ${tx.txId}:`, error);
            }
          }
        }
        
        if (uncategorizedTxs.length > 5) {
          botMessage += `... and ${uncategorizedTxs.length - 5} more transactions\n\n`;
        }
        
        botMessage += `üí¨ Say something like "categorize tx_123 as delights" to manually categorize, or I can auto-categorize high-confidence suggestions for you!`;
      }
      
      // Handle explicit transaction ID categorization
      const txIdPattern = /tx_(\w+)/g;
      let txMatch;
      const autoFunctionCalls = [];
      
      while ((txMatch = txIdPattern.exec(message)) !== null) {
        const txId = `tx_${txMatch[1]}`;
        
        // Determine category based on transaction context in the message
        let suggestion = 'wild_cards';
        let confidence = 0.6;
        
        const lowerMessage = message.toLowerCase();
        if (lowerMessage.includes('delights') || lowerMessage.includes('entertainment')) {
          suggestion = 'delights';
          confidence = 0.9;
        } else if (lowerMessage.includes('foundations') || lowerMessage.includes('essential')) {
          suggestion = 'foundations';
          confidence = 0.9;
        } else if (lowerMessage.includes('nest_egg') || lowerMessage.includes('saving')) {
          suggestion = 'nest_egg';
          confidence = 0.9;
        } else if (lowerMessage.includes('wild_cards') || lowerMessage.includes('misc')) {
          suggestion = 'wild_cards';
          confidence = 0.9;
        }
        
        autoFunctionCalls.push({ name: 'suggestCategory', args: { txId, suggestion, confidence } });
        
        // Execute the function call
        try {
          console.log(`üîß DEBUG: Auto-executing suggestCategory - ${txId}: ${suggestion} (${confidence})`);
          await convexService.suggestCategory(txId, suggestion, confidence);
          console.log('üîß DEBUG: Category suggested successfully');
        } catch (error) {
          console.error(`üîß DEBUG: Error executing auto suggestCategory:`, error);
        }
      }
      
      if (autoFunctionCalls.length > 0) {
        botMessage += `\n\n‚úÖ I've categorized ${autoFunctionCalls.length} transaction${autoFunctionCalls.length > 1 ? 's' : ''} for you:\n`;
        autoFunctionCalls.forEach(call => {
          const { txId, suggestion, confidence } = call.args;
          botMessage += `‚Ä¢ ${txId}: **${suggestion}** (${Math.round(confidence * 100)}% confidence)\n`;
        });
      }
      
    } catch (error) {
      console.error('üîß DEBUG: Error in transaction categorization:', error);
      botMessage += `\n\n‚ùå I had trouble accessing your transaction data. Please make sure your bank account is connected.`;
    }
  }
  
  // Send the response
  res.json({
    message: botMessage,
    timestamp: new Date().toISOString(),
    hasFinancialData: false
  });
}

const app = express();
const PORT = process.env.PORT || 3001;

// Create HTTP server
const server = http.createServer(app);

// Create WebSocket server
const wss = new WebSocket.Server({ server });

app.use(cors({
  origin: ['http://localhost:3000', 'http://127.0.0.1:3000'],
  methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
  allowedHeaders: ['Content-Type', 'Authorization'],
  credentials: true
}));
app.use(express.json());

// AI Provider Configuration
const USE_OLLAMA = process.env.USE_OLLAMA === 'true';
const OLLAMA_URL = process.env.OLLAMA_URL || 'http://127.0.0.1:11434';
const OLLAMA_MODEL = process.env.OLLAMA_MODEL || 'qwen2.5:1.5b';

let aiService;

if (USE_OLLAMA) {
  console.log('ü¶ô Using Ollama AI Service');
  aiService = new OllamaService(OLLAMA_URL, OLLAMA_MODEL);
} else {
  console.log('üîë GOOGLE_AI_API_KEY exists:', !!process.env.GOOGLE_AI_API_KEY);
  aiService = new GoogleGenAI({
    apiKey: process.env.GOOGLE_AI_API_KEY
  });
  console.log('‚úÖ GoogleGenAI initialized successfully');
}

// Initialize OpenAI for Whisper STT
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Configure multer for file uploads
const upload = multer({ 
  storage: multer.memoryStorage(),
  limits: {
    fileSize: 10 * 1024 * 1024, // 10MB limit
  }
});

if (!process.env.GOOGLE_AI_API_KEY) {
  console.error('GOOGLE_AI_API_KEY is required. Please set it in your .env file.');
  process.exit(1);
}

// Warn if Cartesia is not configured (voice features will be disabled)
if (!process.env.CARTESIA_API_KEY) {
  console.warn('‚ö†Ô∏è  CARTESIA_API_KEY not set. Voice chat features will be disabled.');
}

// Initialize Gemini Live Streaming service
const geminiLiveStreaming = new GeminiLiveStreamingService();

// Store active voice sessions for real-time conversation
const voiceSessions = new Map();
const geminiLiveSessions = new Map();

class RealTimeVoiceSession {
  constructor(sessionId, userId = 'default', accessToken = null) {
    this.sessionId = sessionId;
    this.userId = userId;
    this.accessToken = accessToken;
    this.isActive = false;
    this.conversationHistory = [];
    this.dailyRoom = null;
    this.wsConnection = null;
    this.isProcessing = false;
    this.audioChunkBuffer = [];
    this.speechTimer = null;
    this.speechDelay = 2000; // Wait 2 seconds after speech stops before processing
    this.lastTranscript = '';
    this.accumulatedTranscripts = [];
    
    console.log(`üé§ Created real-time voice session: ${sessionId}`);
  }

  async initialize() {
    try {
      // Create Daily.co room for WebRTC transport
      if (process.env.DAILY_API_KEY) {
        this.dailyRoom = await this.createDailyRoom();
      }
      
      // Initialize conversation context for real-time interaction
      this.conversationHistory = [{
        role: "system",
        content: `You are Finley, a friendly financial AI assistant in a REAL-TIME voice conversation.

        Guidelines for voice responses:
        - Keep responses under 2-3 sentences
        - Be conversational and natural
        - Respond quickly and concisely
        - Support interruption gracefully
        - Be empathetic about financial topics
        - Ask follow-up questions to keep conversation flowing
        
        You can be interrupted mid-sentence, so avoid long explanations unless specifically requested.`
      }];

      this.isActive = true;
      console.log(`‚úÖ Real-time voice session ${this.sessionId} initialized`);
      
      return {
        sessionId: this.sessionId,
        dailyRoom: this.dailyRoom,
        status: 'active'
      };
      
    } catch (error) {
      console.error(`‚ùå Failed to initialize voice session ${this.sessionId}:`, error);
      throw error;
    }
  }

  async createDailyRoom() {
    try {
      const roomName = `finley-voice-${this.sessionId}`;
      
      const response = await fetch('https://api.daily.co/v1/rooms', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.DAILY_API_KEY}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          name: roomName,
          properties: {
            max_participants: 2,
            enable_chat: false,
            enable_screenshare: false,
            enable_recording: false,
            start_video_off: true,
            start_audio_off: false,
            enable_prejoin_ui: false,
            enable_network_ui: false,
            owner_only_broadcast: false
          }
        })
      });

      if (!response.ok) {
        throw new Error(`Daily.co room creation failed: ${response.status}`);
      }

      const roomData = await response.json();
      console.log(`‚úÖ Created Daily.co room: ${roomData.url}`);
      
      return {
        url: roomData.url,
        name: roomData.name,
        userToken: await this.createDailyToken(roomData.url, 'user'),
        botToken: await this.createDailyToken(roomData.url, 'finley_bot')
      };

    } catch (error) {
      console.error('‚ùå Daily.co room creation error:', error);
      // Return fallback for direct WebSocket connection
      return null;
    }
  }

  async createDailyToken(roomUrl, userName) {
    try {
      const roomName = roomUrl.split('/').pop();
      
      const response = await fetch('https://api.daily.co/v1/meeting-tokens', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.DAILY_API_KEY}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          properties: {
            room_name: roomName,
            user_name: userName,
            is_owner: userName === 'finley_bot',
            enable_recording: false
          }
        })
      });

      if (!response.ok) {
        throw new Error(`Daily.co token creation failed: ${response.status}`);
      }

      const data = await response.json();
      return data.token;

    } catch (error) {
      console.error('‚ùå Daily.co token creation error:', error);
      return null;
    }
  }

  setWebSocketConnection(ws) {
    this.wsConnection = ws;
    console.log(`üîó WebSocket connected to voice session ${this.sessionId}`);
  }

  debouncedProcessSpeech(transcript) {
    // Clear existing timer
    if (this.speechTimer) {
      clearTimeout(this.speechTimer);
    }
    
    // Accumulate transcripts to build complete sentences
    if (transcript && transcript.trim().length > 0) {
      this.accumulatedTranscripts.push(transcript.trim());
      console.log(`üìù Accumulated: "${transcript.trim()}" (${this.accumulatedTranscripts.length} parts)`);
    }
    
    // Set new timer to process after speech delay
    this.speechTimer = setTimeout(async () => {
      if (this.accumulatedTranscripts.length > 0) {
        // Combine all accumulated transcripts into one coherent sentence
        const fullTranscript = this.accumulatedTranscripts.join(' ').trim();
        console.log(`‚è±Ô∏è Processing debounced speech: "${fullTranscript}"`);
        
        await this.processVoiceInput(fullTranscript, this.accessToken);
        
        // Clear accumulated transcripts
        this.accumulatedTranscripts = [];
      }
    }, this.speechDelay);
    
    console.log(`‚è≥ Speech debounced, waiting ${this.speechDelay}ms for more input...`);
  }

  async processVoiceInput(transcript, accessToken = null) {
    if (this.isProcessing) {
      console.log(`üõë Interruption detected in session ${this.sessionId}`);
      this.isProcessing = false;
      // Allow immediate processing of new input
    }

    this.isProcessing = true;

    try {
      console.log(`üë§ User (${this.sessionId}): ${transcript}`);
      
      // Add user message to conversation history
      this.conversationHistory.push({
        role: "user",
        content: transcript
      });

      // Get AI response using existing genAI service with financial context
      const aiResponse = await this.getAIResponse(accessToken || this.accessToken);
      console.log(`ü§ñ Finley (${this.sessionId}): ${aiResponse}`);

      // Convert to speech and send response
      await this.sendVoiceResponse(transcript, aiResponse);

      this.isProcessing = false;
      return aiResponse;

    } catch (error) {
      console.error(`‚ùå Error processing voice input for session ${this.sessionId}:`, error);
      this.isProcessing = false;
      
      const errorResponse = "I'm sorry, I had trouble processing that. Could you try again?";
      await this.sendVoiceResponse(transcript, errorResponse);
      return errorResponse;
    }
  }

  async getAIResponse(accessToken = null) {
    try {
      // Get financial context if access token is available
      let financialContext = '';
      if (accessToken) {
        try {
          console.log('ü§ñ Fetching financial data for voice AI context...');
          const financialData = await getFinancialSummary(accessToken);
          
          financialContext = `
=== FINANCIAL CONTEXT FROM CONNECTED PLAID ACCOUNT (Last 30 days) ===

ACCOUNT BALANCES:
${financialData.balances.map(acc => `- ${acc.name} (${acc.type}): $${acc.balances.current || 'N/A'}`).join('\n')}

SUMMARY STATISTICS:
- Total Balance Across All Accounts: $${financialData.summary.totalBalance}
- Total Spending in Period: $${financialData.summary.monthlySpending}
- Number of Transactions Found: ${financialData.summary.transactionCount}

TOP SPENDING CATEGORIES (AI-powered custom categorization):
${financialData.summary.topCategories.length > 0 ? 
  financialData.summary.topCategories.map(cat => 
    `- ${cat.category}: $${cat.amount} (${cat.subcategories.map(sub => `${sub.subcategory}: $${sub.amount}`).join(', ')})`
  ).join('\n') : 
  '- No transactions found in this period'}

=== END OF ACTUAL FINANCIAL DATA ===`;
        } catch (error) {
          console.error('‚ùå Error fetching financial data for voice:', error);
          financialContext = '\nNote: Unable to fetch current financial data for this conversation.';
        }
      }

      // Voice-optimized system prompt with financial context
      const systemPrompt = `
‚ú®  FINLEY ‚Äì Voice Financial Assistant
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

You are Finley, a warm voice assistant helping with financial questions.

VOICE RESPONSE RULES:
‚Ä¢ Keep responses under 3 sentences for real-time conversation
‚Ä¢ Use plain text only - no HTML formatting for voice synthesis
‚Ä¢ No charts in voice responses - describe data instead
‚Ä¢ Be warm and encouraging, like talking to a friend

DATA RULES (CRITICAL):
1. Only discuss facts from FINANCIAL CONTEXT or calculations from those facts
2. Never fabricate, guess, or estimate any financial data
3. If data isn't available, say "I don't have that information from your connected account"
4. No financial advice or product recommendations

TONE: Conversational, warm, and supportive - like a knowledgeable friend helping with money questions.

FINANCIAL CONTEXT:
${financialContext}`;

      // Keep conversation history manageable for real-time responses
      const recentHistory = this.conversationHistory.slice(-6);
      
      let prompt = systemPrompt;
      if (recentHistory.length > 1) {
        const historyText = recentHistory.slice(1).map(msg => 
          `${msg.role === 'user' ? 'User' : 'Finley'}: ${msg.content}`
        ).join('\n');
        prompt += `\n\nPrevious conversation:\n${historyText}`;
      }

      const response = await genAI.models.generateContent({
        model: 'gemini-2.5-flash-preview-05-20',
        contents: prompt,
      });

      const aiText = response.text || "I'm here to help with your financial questions.";
      
      // Add to conversation history
      this.conversationHistory.push({
        role: "assistant",
        content: aiText
      });

      return aiText;

    } catch (error) {
      console.error('‚ùå AI response error:', error);
      return "I'm having trouble right now. Could you please try again?";
    }
  }

  async sendVoiceResponse(userInput, aiResponse) {
    try {
      // Convert AI response to speech
      let audioData = null;
      if (process.env.CARTESIA_API_KEY) {
        try {
          const audioBuffer = await textToSpeech(aiResponse);
          audioData = audioBuffer.toString('base64');
          console.log(`üîä Generated speech for session ${this.sessionId} (${audioBuffer.length} bytes)`);
        } catch (ttsError) {
          console.error('‚ùå TTS Error:', ttsError);
        }
      }

      // Send response via WebSocket
      if (this.wsConnection && this.wsConnection.readyState === 1) {
        this.wsConnection.send(JSON.stringify({
          type: 'voice_response',
          sessionId: this.sessionId,
          userInput,
          aiResponse,
          audioData,
          timestamp: new Date().toISOString(),
          canInterrupt: true
        }));
        console.log(`‚úÖ Voice response sent for session ${this.sessionId}`);
      }

    } catch (error) {
      console.error(`‚ùå Error sending voice response for session ${this.sessionId}:`, error);
    }
  }

  async destroy() {
    this.isActive = false;
    this.isProcessing = false;
    
    // Clear speech timer
    if (this.speechTimer) {
      clearTimeout(this.speechTimer);
      this.speechTimer = null;
    }
    
    // Close WebSocket connection
    if (this.wsConnection) {
      this.wsConnection.close();
      this.wsConnection = null;
    }
    
    console.log(`üóëÔ∏è Real-time voice session ${this.sessionId} destroyed`);
  }
}

app.post('/api/chat', async (req, res) => {
  try {
    console.log('üîß DEBUG: Chat endpoint called');
    const { message, conversationHistory = [], accessToken, accountBalances } = req.body || {};
    console.log('üîß DEBUG: Request parsed successfully, message:', message);

    if (!message) {
      return res.status(400).json({ error: 'Message is required' });
    }
    
    // Check for transaction categorization keywords
    const shouldCategorize = message.toLowerCase().includes('categor') || 
                            message.toLowerCase().includes('tx_') ||
                            message.toLowerCase().includes('transaction') ||
                            message.toLowerCase().includes('uncategorized') ||
                            message.toLowerCase().includes('budget');
    
    if (shouldCategorize) {
      console.log('üîß DEBUG: Checking for uncategorized transactions...');
      
      try {
        const userId = USE_TEST_USER ? TEST_USER_ID : 'default_user';
        const uncategorizedTxs = await convexService.getUncategorizedTransactions(userId);
        console.log(`üîß DEBUG: Found ${uncategorizedTxs.length} uncategorized transactions`);
        
        if (uncategorizedTxs.length > 0) {
          let botMessage = `üí° I found ${uncategorizedTxs.length} uncategorized transaction${uncategorizedTxs.length > 1 ? 's' : ''} that need${uncategorizedTxs.length === 1 ? 's' : ''} your attention:\n\n`;
          
          const transactionsToShow = uncategorizedTxs.slice(0, 5);
          
          for (const tx of transactionsToShow) {
            const amount = Math.abs(tx.amount || 0);
            const merchant = tx.enrichedMerchantName || tx.merchantName || tx.description || 'Unknown';
            const date = new Date(tx.date).toLocaleDateString();
            
            botMessage += `<div class="transaction-item">
              <h4>${merchant} - $${amount}</h4>
              <p>Date: ${date}</p>
              <p>Transaction ID: ${tx.transaction_id}</p>
              <div class="category-buttons">
                <button onclick="categorizeTransaction('${tx.transaction_id}', 'foundations')">üè† Foundations</button>
                <button onclick="categorizeTransaction('${tx.transaction_id}', 'delights')">üéâ Delights</button>
                <button onclick="categorizeTransaction('${tx.transaction_id}', 'nest_egg')">ü•ö Nest Egg</button>
                <button onclick="categorizeTransaction('${tx.transaction_id}', 'wild_cards')">üéØ Wild Cards</button>
              </div>
            </div>\n`;
          }
          
          return res.json({
            message: convertToHTML(botMessage),
            timestamp: new Date().toISOString(),
            hasFinancialData: !!accessToken
          });
        }
      } catch (error) {
        console.error('Error fetching uncategorized transactions:', error);
      }
    }

    // Build financial context
    let financialContext = '';
    
    // Use account balance data sent from frontend if available
    if (accountBalances && accountBalances.length > 0) {
      console.log('üîß DEBUG: Using account balances from frontend:', accountBalances.length, 'accounts');
      
      const totalBalance = accountBalances.reduce((sum, acc) => sum + (acc.balances?.current || 0), 0);
      const checkingAccount = accountBalances.find(acc => acc.subtype === 'checking');
      const savingsAccount = accountBalances.find(acc => acc.subtype === 'savings');
      
      let accountDetails = `‚Ä¢ Total Balance: $${totalBalance.toFixed(2)}\n`;
      if (checkingAccount) {
        accountDetails += `‚Ä¢ Checking Account: $${checkingAccount.balances.current} (${checkingAccount.name})\n`;
      }
      if (savingsAccount) {
        accountDetails += `‚Ä¢ Savings Account: $${savingsAccount.balances.current} (${savingsAccount.name})\n`;
      }
      
      financialContext = `
CURRENT FINANCIAL DATA:
${accountDetails}‚Ä¢ ${accountBalances.length} accounts connected
‚Ä¢ Account Connection: Active via Plaid`;
    }

    // Build conversation prompt
    let prompt = `You are Finley, a friendly financial AI assistant powered by advanced AI technology. I can help you understand your spending patterns and provide financial insights.`;
    
    if (financialContext) {
      prompt += `\n\n${financialContext}`;
    }
    
    prompt += `\n\nConversation Guidelines:
- Be helpful, friendly, and conversational
- Use specific financial data when available
- Format responses with HTML tags for better display
- Keep responses concise but informative
- Always use actual account numbers and balances when answering balance questions

IMPORTANT: Format your response using HTML tags. Use <h3> for headings and <p> tags for paragraphs. Be concise and helpful.`;

    if (conversationHistory && conversationHistory.length > 0) {
      const historyText = conversationHistory
        .map(msg => `${msg.sender === 'user' ? 'User' : 'Assistant'}: ${msg.text}`)
        .join('\n');
      prompt += `\n\nPrevious conversation:\n${historyText}`;
    }
    
    prompt += `\n\nUser: ${message}\n\nAssistant:`;

    console.log('üîß DEBUG: Using AI service:', USE_OLLAMA ? 'Ollama' : 'Google AI');
    
    let response;
    if (USE_OLLAMA) {
      response = await aiService.generateContent(prompt);
    } else {
      const model = aiService.getGenerativeModel({ model: 'gemini-2.5-pro-preview-05-06' });
      response = await model.generateContent(prompt);
    }

    let botMessage = response.response.text();
    console.log('ü§ñ AI Response received:', botMessage.substring(0, 200) + '...');

    return res.json({
      message: convertToHTML(botMessage),
      timestamp: new Date().toISOString(),
      hasFinancialData: !!accessToken
    });
        
  } catch (error) {
    console.error('üîß DEBUG: Chat Error:', error);
    return res.status(500).json({
      error: 'Internal server error',
      message: error.message
    });
  }
});
                  type: Type.STRING,
                  description: "AI analysis or reasoning for this budget setting"
                }
              },
              required: ["category", "budgetAmount"]
            }
          }, {
            name: "suggestCategory",
            description: "Suggest a budget category for a transaction",
            parameters: {
              type: Type.OBJECT,
              properties: {
                txId: {
                  type: Type.STRING,
                  description: "Transaction ID from Plaid"
                },
                suggestion: {
                  type: Type.STRING,
                  enum: ["foundations", "delights", "nest_egg", "wild_cards"],
                  description: "Suggested budget category for this transaction"
                },
                confidence: {
                  type: Type.NUMBER,
                  description: "Confidence level between 0.0 and 1.0 for this categorization"
                }
              },
              required: ["txId", "suggestion", "confidence"]
            }
          }, {
            name: "approveCategory",
            description: "Approve and finalize a category for a transaction after user confirmation",
            parameters: {
              type: Type.OBJECT,
              properties: {
                txId: {
                  type: Type.STRING,
                  description: "Transaction ID from Plaid"
                },
                finalCategory: {
                  type: Type.STRING,
                  enum: ["foundations", "delights", "nest_egg", "wild_cards"],
                  description: "Final approved budget category for this transaction"
                }
              },
              required: ["txId", "finalCategory"]
            }
          }]
        }];

        try {
          // Build conversation context with history
          const contents = [];
          
          // Get financial data for context - prioritize frontend-provided data
          let financialContext = '';
          
          // Use account balance data sent from frontend if available
          if (accountBalances && accountBalances.length > 0) {
            console.log('üîß DEBUG: Using account balances from frontend:', accountBalances.length, 'accounts');
            
            const totalBalance = accountBalances.reduce((sum, acc) => sum + (acc.balances?.current || 0), 0);
            const checkingAccount = accountBalances.find(acc => acc.subtype === 'checking');
            const savingsAccount = accountBalances.find(acc => acc.subtype === 'savings');
            
            let accountDetails = `‚Ä¢ Total Balance: $${totalBalance.toFixed(2)}\n`;
            if (checkingAccount) {
              accountDetails += `‚Ä¢ Checking Account: $${checkingAccount.balances.current} (${checkingAccount.name})\n`;
            }
            if (savingsAccount) {
              accountDetails += `‚Ä¢ Savings Account: $${savingsAccount.balances.current} (${savingsAccount.name})\n`;
            }
            
            if (USE_TEST_USER) {
              try {
                const sampleTxs = await convexService.getUncategorizedTransactions(TEST_USER_ID);
                financialContext = `
CURRENT FINANCIAL DATA (TEST MODE):
${accountDetails}‚Ä¢ Sample Transactions: ${sampleTxs.length} uncategorized in Convex
‚Ä¢ Account Connection: Connected to Plaid + Convex test data
`;
              } catch (error) {
                financialContext = `
CURRENT FINANCIAL DATA (TEST MODE):
${accountDetails}‚Ä¢ Account Connection: Connected to Plaid
`;
              }
            } else {
              financialContext = `
CURRENT FINANCIAL DATA:
${accountDetails}‚Ä¢ Account Connection: Connected to Plaid
`;
            }
          } else if (accessToken) {
            // Fallback to fetching financial data if not provided by frontend
            try {
              const financialData = await getFinancialSummary(accessToken);
              if (financialData) {
                if (USE_TEST_USER) {
                  const sampleTxs = await convexService.getUncategorizedTransactions(TEST_USER_ID);
                  financialContext = `
CURRENT FINANCIAL DATA (TEST MODE):
‚Ä¢ Total Balance: $${financialData.totalBalance || 0} (from Plaid)
‚Ä¢ Sample Transactions: ${sampleTxs.length} uncategorized in Convex
‚Ä¢ Account Connection: Connected to Plaid + Convex test data
`;
                } else {
                  financialContext = `
CURRENT FINANCIAL DATA:
‚Ä¢ Total Balance: $${financialData.totalBalance || 0}
‚Ä¢ Monthly Spending: $${financialData.summary?.monthlySpending || 0}
‚Ä¢ Recent Transactions: ${financialData.recentTransactions?.length || 0} available
‚Ä¢ Account Connection: Connected to Plaid
`;
                }
              }
            } catch (error) {
              console.log('Could not fetch financial context:', error.message);
              console.log('üîß DEBUG: Error details:', error.data);
              
              // Even if full financial summary fails, try to get just account balances
              try {
                console.log('üîß DEBUG: Attempting to get account balances only...');
                const { getAccountBalances } = require('./plaidClient');
                const balances = await getAccountBalances(accessToken);
                
                if (balances && balances.length > 0) {
                  const totalBalance = balances.reduce((sum, acc) => sum + (acc.balances.current || 0), 0);
                  const checkingAccount = balances.find(acc => acc.subtype === 'checking');
                  
                  financialContext = `
ACCOUNT BALANCE DATA:
‚Ä¢ Total Balance: $${totalBalance.toFixed(2)}
‚Ä¢ Checking Account: $${checkingAccount ? checkingAccount.balances.current : 'N/A'}
‚Ä¢ ${balances.length} accounts connected
‚Ä¢ Account Connection: Connected to Plaid (balance data only)
`;
                  console.log('üîß DEBUG: Successfully got balance data:', financialContext);
                } else {
                  throw new Error('No balance data available');
                }
              } catch (balanceError) {
                console.log('üîß DEBUG: Balance fetch also failed:', balanceError.message);
                if (USE_TEST_USER) {
                  // Final fallback to sample data
                  try {
                    const sampleTxs = await convexService.getUncategorizedTransactions(TEST_USER_ID);
                    financialContext = `
CURRENT FINANCIAL DATA (TEST MODE - FALLBACK):
‚Ä¢ Sample Transactions: ${sampleTxs.length} available in Convex
‚Ä¢ Account Connection: Using test data only
`;
                  } catch (fallbackError) {
                    console.log('Could not fetch sample transaction context:', fallbackError.message);
                  }
                }
              }
            }
          }

          // Add system message with strict HTML formatting
          console.log('üîß DEBUG: Financial context being provided to AI:');
          console.log(financialContext || 'NO FINANCIAL CONTEXT PROVIDED');
          
          contents.push({
            role: "user",
            parts: [{
              text: `You are Finley, a financial assistant. You MUST ALWAYS respond using HTML formatting.

CRITICAL RULE: Your response MUST start with an HTML tag like <h3> or <p>. NO plain text allowed.

${financialContext}

IMPORTANT: You have access to the user's financial data shown above. When they ask about account balances, use the specific dollar amounts from the financial data. You are authorized to share this information as it's their own data.

MANDATORY FORMAT:
- Start every response with <h3>Title</h3>
- Use <p> for text, <strong> for emphasis
- Keep responses under 50 words
- End with </p>

For charts, add JSON after HTML:
{"type": "spending_breakdown", "chartType": "auto"}

EXAMPLES:
Input: "Show spending"
Output: <h3>üìä Spending Breakdown</h3><p>Creating your spending visualization now.</p>
{"type": "spending_breakdown", "chartType": "auto"}

Input: "Budget help"
Output: <h3>üí∞ Budget Help</h3><p>I can help create your budget! What's your monthly income?</p>

MUST start with HTML tag. NEVER use plain text.`
            }]
          });
          
          // Add conversation history if available
          if (conversationHistory && conversationHistory.length > 0) {
            conversationHistory.forEach(msg => {
              contents.push({
                role: msg.sender === 'user' ? 'user' : 'model',
                parts: [{ text: msg.text }]
              });
            });
          }
          
          // Add current user message with HTML formatting reminder
          contents.push({
            role: "user",
            parts: [{ text: `${message}

IMPORTANT: Format your response using HTML tags. Start with <h3> and use <p> tags. Be concise.` }]
          });
          
          // Try with latest model and proper tools - force function calling for transactions
          const shouldForceFunctions = message.toLowerCase().includes('purchase') || 
                                      message.toLowerCase().includes('transaction') ||
                                      message.toLowerCase().includes('categor');
          
          if (USE_OLLAMA) {
            response = await aiService.generateContent({ contents });
          } else {
            const model = genAI.getGenerativeModel({ 
              model: 'gemini-2.5-flash-preview-05-20',
              tools: tools,
              toolConfig: { 
                functionCallingConfig: { 
                  mode: shouldForceFunctions ? 'ANY' : 'AUTO',
                  allowedFunctionNames: shouldForceFunctions ? ['suggestCategory'] : undefined
                } 
              }
            });
            response = await model.generateContent(contents);
          }
        } catch (modelError) {
          console.log('üîß DEBUG: Latest model failed, trying fallback without tools...');
          // Fallback without tools for now
          if (USE_OLLAMA) {
            response = await aiService.generateContent(`You are Finley, a helpful financial assistant. The user said: "${message}". Respond helpfully about budgets.`);
          } else {
            response = await genAI.models.generateContent({
              model: 'gemini-2.0-flash-exp',
              contents: [
                {
                  role: "user", 
                  parts: [{ text: `You are Finley, a helpful financial assistant. The user said: "${message}". Respond helpfully about budgets.` }]
                }
              ]
            });
          }
        }
      }
      
      console.log('üîß DEBUG: generateContent completed successfully');
      console.log('üîß DEBUG: response structure:', Object.keys(response || {}));
      // Reduced debug output to prevent memory issues
      // console.log('üîß DEBUG: full response:', JSON.stringify(response, null, 2));
      
      // Check for function calls in response
      console.log('üîß DEBUG: response object keys:', Object.keys(response));
      const candidate = response.candidates?.[0];
      // console.log('üîß DEBUG: candidate structure:', JSON.stringify(candidate, null, 2));
      
      // Try multiple ways to get function calls
      let functionCalls = [];
      if (response.functionCalls) {
        functionCalls = response.functionCalls;
        console.log('üîß DEBUG: Found functionCalls in response root');
      } else if (candidate?.content?.parts) {
        functionCalls = candidate.content.parts.filter(part => part.functionCall);
        console.log('üîß DEBUG: Found functionCall parts:', functionCalls.length);
      } else if (candidate?.functionCall) {
        functionCalls = [candidate.functionCall];
        console.log('üîß DEBUG: Found functionCall in candidate');
      }
      
      let botMessage;
      
      if (functionCalls && functionCalls.length > 0) {
        console.log('üîß DEBUG: Function calls detected:', functionCalls);
        
        // Process function calls
        for (const functionCall of functionCalls) {
          // Handle both old and new response formats
          const call = functionCall.functionCall || functionCall;
          if (call.name === 'setBudget') {
            const { category, budgetAmount, aiAnalysis } = call.args;
            console.log(`üîß DEBUG: Setting budget - ${category}: $${budgetAmount}`);
            
            try {
              // Call the actual budget setting function
              const result = await convexService.setBudget(
                USE_TEST_USER ? TEST_USER_ID : null,
                category,
                budgetAmount,
                aiAnalysis || `AI set budget for ${category}`
              );
              console.log('üîß DEBUG: Budget set successfully:', result);
            } catch (error) {
              console.error('üîß DEBUG: Budget setting error:', error);
            }
          } else if (call.name === 'suggestCategory') {
            const { txId, suggestion, confidence } = call.args;
            console.log(`üîß DEBUG: Suggesting category - ${txId}: ${suggestion} (${confidence})`);
            
            try {
              const result = await convexService.suggestCategory(txId, suggestion, confidence);
              console.log('üîß DEBUG: Category suggested successfully:', result);
            } catch (error) {
              console.error('üîß DEBUG: Category suggestion error:', error);
            }
          } else if (call.name === 'approveCategory') {
            const { txId, finalCategory } = call.args;
            console.log(`üîß DEBUG: Approving category - ${txId}: ${finalCategory}`);
            
            try {
              const result = await convexService.approveCategory(txId, finalCategory);
              console.log('üîß DEBUG: Category approved successfully:', result);
            } catch (error) {
              console.error('üîß DEBUG: Category approval error:', error);
            }
          }
        }
        
        // Generate response based on function call type
        const firstCall = functionCalls[0].functionCall || functionCalls[0];
        if (firstCall.name === 'setBudget') {
          botMessage = `‚úÖ I've set your ${firstCall.args.category} budget to $${firstCall.args.budgetAmount} per month. This budget will help you manage your ${firstCall.args.category === 'foundations' ? 'essential expenses' : firstCall.args.category === 'delights' ? 'fun spending' : firstCall.args.category === 'nest_egg' ? 'savings goals' : 'emergency funds'}.`;
        } else if (firstCall.name === 'suggestCategory') {
          const confidence = firstCall.args.confidence;
          if (confidence >= 0.6) {
            botMessage = `I've automatically categorized this transaction as "${firstCall.args.suggestion}" with ${Math.round(confidence * 100)}% confidence.`;
          } else {
            botMessage = `I think this transaction should go in "${firstCall.args.suggestion}" but I'm only ${Math.round(confidence * 100)}% confident. Would you like me to categorize it this way?`;
          }
        } else if (firstCall.name === 'approveCategory') {
          botMessage = `‚úÖ Great! I've categorized this transaction as "${firstCall.args.finalCategory}".`;
        } else {
          botMessage = 'Function call processed successfully.';
        }
      } else {
        // Regular text response - parse for function calls and budget setting intent
        if (candidate?.content?.parts?.[0]?.text) {
          let rawMessage = candidate.content.parts[0].text;
          
          // Convert plain text to HTML formatting since AI won't follow HTML instructions
          console.log('üîß DEBUG: Converting to HTML...');
          console.log('üîß DEBUG: Raw message length:', rawMessage.length);
          botMessage = convertToHTML(rawMessage);
          console.log('üîß DEBUG: HTML message length:', botMessage.length);
          console.log('üîß DEBUG: HTML preview:', botMessage.substring(0, 100));
          
          // Parse FUNCTION_CALL patterns in the response
          const functionCallPattern = /FUNCTION_CALL:\s*(\w+)\(([^)]+)\)/g;
          let match;
          const parsedFunctionCalls = [];
          
          while ((match = functionCallPattern.exec(botMessage)) !== null) {
            const functionName = match[1];
            const argsString = match[2];
            
            console.log(`üîß DEBUG: Found function call: ${functionName}(${argsString})`);
            
            // Parse arguments
            const args = {};
            const argPattern = /(\w+)=["']?([^"',]+)["']?/g;
            let argMatch;
            while ((argMatch = argPattern.exec(argsString)) !== null) {
              const key = argMatch[1];
              let value = argMatch[2];
              
              // Convert numeric values
              if (key === 'confidence' && !isNaN(value)) {
                value = parseFloat(value);
              }
              args[key] = value;
            }
            
            parsedFunctionCalls.push({ name: functionName, args });
            
            // Execute the function call
            try {
              if (functionName === 'suggestCategory') {
                const { txId, suggestion, confidence } = args;
                console.log(`üîß DEBUG: Executing suggestCategory - ${txId}: ${suggestion} (${confidence})`);
                await convexService.suggestCategory(txId, suggestion, confidence);
                console.log('üîß DEBUG: Category suggested successfully');
              } else if (functionName === 'approveCategory') {
                const { txId, finalCategory } = args;
                console.log(`üîß DEBUG: Executing approveCategory - ${txId}: ${finalCategory}`);
                await convexService.approveCategory(txId, finalCategory);
                console.log('üîß DEBUG: Category approved successfully');
              }
            } catch (error) {
              console.error(`üîß DEBUG: Error executing ${functionName}:`, error);
            }
          }
          
          console.log('üîß DEBUG: Checking auto-generation conditions...');
          console.log('üîß DEBUG: parsedFunctionCalls.length:', parsedFunctionCalls.length);
          console.log('üîß DEBUG: message contains categor:', message.toLowerCase().includes('categor'));
          console.log('üîß DEBUG: message contains tx_:', message.toLowerCase().includes('tx_'));
          console.log('üîß DEBUG: message contains transaction:', message.toLowerCase().includes('transaction'));
          
          // If no function calls found but user is asking about transaction categorization, handle it
          if (parsedFunctionCalls.length === 0 && 
              (message.toLowerCase().includes('categor') || 
               message.toLowerCase().includes('tx_') ||
               message.toLowerCase().includes('transaction'))) {
            
            console.log('üîß DEBUG: Auto-generating function calls for transaction categorization');
            
            // First, try to show uncategorized transactions
            console.log('üîß DEBUG: Checking for uncategorized transactions...');
            
            try {
              const userId = USE_TEST_USER ? TEST_USER_ID : 'default_user';
              
              // Get ALL transactions from Convex (not just uncategorized)
              const allTxs = await convexService.listTransactions(userId);
              const uncategorizedTxs = await convexService.getUncategorizedTransactions(userId);
              console.log(`üîß DEBUG: Found ${allTxs.length} total transactions, ${uncategorizedTxs.length} uncategorized`);
              
              if (allTxs.length > 0) {
                // Replace the generic AI response with transaction-specific response
                console.log('üîß DEBUG: Replacing AI response with transaction data');
                
                let transactionMessage = `
<h3>üí≥ Your Recent Transactions</h3>
<p>${allTxs.length} transaction${allTxs.length > 1 ? 's' : ''} found ‚Ä¢ ${uncategorizedTxs.length} need${uncategorizedTxs.length === 1 ? 's' : ''} categorization</p>
<div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 10px 0;">`;
                
                const transactionsToShow = allTxs.slice(0, 5); // Show first 5
                
                for (const tx of transactionsToShow) {
                  const amount = Math.abs(tx.amount || 0);
                  const merchant = tx.merchant || 'Unknown';
                  const date = new Date(tx.date).toLocaleDateString();
                  
                  // Determine display based on current status
                  let displayCategory, categoryColor, statusText;
                  
                  if (tx.isApproved && tx.category) {
                    // Already categorized
                    displayCategory = tx.category;
                    statusText = '‚úÖ Categorized';
                    categoryColor = displayCategory === 'foundations' ? '#4caf50' : 
                                   displayCategory === 'delights' ? '#ff9800' : 
                                   displayCategory === 'nest_egg' ? '#2196f3' : '#9c27b0';
                  } else {
                    // Needs categorization - provide AI suggestion
                    displayCategory = 'wild_cards';
                    let confidence = 0.6;
                    
                    const merchantLower = merchant.toLowerCase();
                    
                    if (merchantLower.includes('starbucks') || merchantLower.includes('coffee') || 
                        merchantLower.includes('netflix') || merchantLower.includes('spotify')) {
                      displayCategory = 'delights';
                      confidence = 0.8;
                    } else if (merchantLower.includes('grocery') || merchantLower.includes('gas') ||
                              merchantLower.includes('rent') || merchantLower.includes('mortgage') ||
                              merchantLower.includes('utility')) {
                      displayCategory = 'foundations';
                      confidence = 0.9;
                    } else if (merchantLower.includes('investment') || merchantLower.includes('saving')) {
                      displayCategory = 'nest_egg';
                      confidence = 0.7;
                    }
                    
                    statusText = `ü§ñ Suggested: **${displayCategory}** (${Math.round(confidence * 100)}% confidence)`;
                    categoryColor = displayCategory === 'foundations' ? '#4caf50' : 
                                   displayCategory === 'delights' ? '#ff9800' : 
                                   displayCategory === 'nest_egg' ? '#2196f3' : '#9c27b0';
                  }
                  
                  transactionMessage += `
<div style="border-left: 4px solid ${categoryColor}; padding-left: 12px; margin: 8px 0;">
  <strong>${tx.txId}</strong> - ${merchant}<br>
  <span style="color: #666;">$${amount.toFixed(2)} on ${date}</span><br>
  <span style="color: ${categoryColor};">${statusText}</span>
</div>`;
                }
                
                transactionMessage += `</div>`;
                
                if (uncategorizedTxs.length > 5) {
                  transactionMessage += `<p><em>... and ${uncategorizedTxs.length - 5} more transactions</em></p>`;
                }
                
                transactionMessage += `<p>üí¨ Say something like <strong>"categorize tx_starbucks_001 as delights"</strong> to manually categorize!</p>`;
                
                // Replace the generic AI response with our transaction-specific response
                botMessage = transactionMessage;
                console.log('üîß DEBUG: botMessage replaced with transaction data');
              }
            } catch (error) {
              console.error('üîß DEBUG: Error retrieving uncategorized transactions:', error);
              botMessage += `\n\n‚ùå I had trouble accessing your transaction data. Please make sure your bank account is connected.`;
            }
            
            // Then extract transaction IDs from the message for specific categorization
            const txIdPattern = /tx_(\w+)/g;
            let txMatch;
            const autoFunctionCalls = [];
            
            while ((txMatch = txIdPattern.exec(message)) !== null) {
              const txId = `tx_${txMatch[1]}`;
              
              // Determine category based on transaction context
              let suggestion = 'wild_cards';
              let confidence = 0.6;
              
              const lowerMessage = message.toLowerCase();
              if (lowerMessage.includes('starbucks') || lowerMessage.includes('coffee') || 
                  lowerMessage.includes('netflix') || lowerMessage.includes('entertainment')) {
                suggestion = 'delights';
                confidence = 0.8;
              } else if (lowerMessage.includes('rent') || lowerMessage.includes('mortgage') || 
                        lowerMessage.includes('grocery') || lowerMessage.includes('gas')) {
                suggestion = 'foundations';
                confidence = 0.9;
              }
              
              autoFunctionCalls.push({ name: 'suggestCategory', args: { txId, suggestion, confidence } });
              
              // Execute the function call
              try {
                console.log(`üîß DEBUG: Auto-executing suggestCategory - ${txId}: ${suggestion} (${confidence})`);
                await convexService.suggestCategory(txId, suggestion, confidence);
                console.log('üîß DEBUG: Category suggested successfully');
              } catch (error) {
                console.error(`üîß DEBUG: Error executing auto suggestCategory:`, error);
              }
            }
            
            if (autoFunctionCalls.length > 0) {
              botMessage += `\n\n‚úÖ I've automatically analyzed and categorized ${autoFunctionCalls.length} transaction${autoFunctionCalls.length > 1 ? 's' : ''} for you:\n`;
              autoFunctionCalls.forEach(call => {
                const { txId, suggestion, confidence } = call.args;
                botMessage += `‚Ä¢ ${txId}: ${suggestion} (${Math.round(confidence * 100)}% confidence)\n`;
              });
            }
          }
          
          // Clean up the response by removing function call patterns
          botMessage = botMessage.replace(functionCallPattern, '').trim();
          
          // If we found function calls, enhance the response
          if (parsedFunctionCalls.length > 0) {
            const categoryCount = parsedFunctionCalls.filter(call => call.name === 'suggestCategory').length;
            if (categoryCount > 0) {
              botMessage += `\n\n‚úÖ I've analyzed and categorized ${categoryCount} transaction${categoryCount > 1 ? 's' : ''} for you!`;
            }
          }
          
          // Check if AI returned a function call as text (fallback parsing)
          const toolCodeMatch = botMessage.match(/setBudget\(category=["']([^"']+)["'],\s*amount=(\d+)\)/) || 
                                botMessage.match(/finley\.setBudget\(category=["']([^"']+)["'],\s*amount=(\d+)\)/) ||
                                botMessage.match(/finances\.setBudget\(category=["']([^"']+)["'],\s*amount=(\d+)\)/);
          
          // Also check if AI says it updated a budget with a specific amount
          const budgetUpdateMatch = botMessage.match(/updated your (nest egg|nest_egg|delights|foundations|wild cards|wild_cards) budget.*?\$(\d+)/i);
          
          if (toolCodeMatch) {
            const category = toolCodeMatch[1];
            const amount = parseInt(toolCodeMatch[2]);
            
            console.log(`üîß DEBUG: Parsing tool call from text - ${category}: $${amount}`);
            
            try {
              // Call the actual budget setting function
              const result = await convexService.setBudget(
                USE_TEST_USER ? TEST_USER_ID : null,
                category,
                amount,
                `AI set budget for ${category} based on conversation`
              );
              console.log('üîß DEBUG: Budget set successfully via tool code parsing:', result);
              
              botMessage = `‚úÖ Perfect! I've set your ${category.replace('_', ' ')} budget to $${amount} per month. This budget will help you manage your ${category === 'foundations' ? 'essential expenses like rent and groceries' : category === 'delights' ? 'fun spending like dining and entertainment' : category === 'nest_egg' ? 'savings and investment goals' : 'emergency funds and unexpected expenses'}.`;
              
            } catch (error) {
              console.error('üîß DEBUG: Budget setting error via tool code parsing:', error);
              botMessage = `I understand you want to set your ${category.replace('_', ' ')} budget to $${amount}, but there was an issue saving it. Please try again.`;
            }
          }
          // Check if AI mentioned updating a budget with a specific amount
          else if (budgetUpdateMatch) {
            let category = budgetUpdateMatch[1].toLowerCase().replace(/\s+/g, '_'); // Convert "nest egg" to "nest_egg"
            const amount = parseInt(budgetUpdateMatch[2]);
            
            console.log(`üîß DEBUG: Parsing budget update from AI response - ${category}: $${amount}`);
            
            try {
              // Call the actual budget setting function
              const result = await convexService.setBudget(
                USE_TEST_USER ? TEST_USER_ID : null,
                category,
                amount,
                `AI updated budget for ${category} based on conversation`
              );
              console.log('üîß DEBUG: Budget updated successfully via response parsing:', result);
              
              // Keep the original AI message since it already describes the update
              
            } catch (error) {
              console.error('üîß DEBUG: Budget update error via response parsing:', error);
              botMessage += '\n\n‚ö†Ô∏è Note: There was an issue saving the budget update. Please try again.';
            }
          }
          // Parse text for budget setting commands (original logic)
          else {
            const budgetRegex = /(delights|foundations|nest_egg|wild_cards|wild cards|nest egg).*?budget.*?\$?(\d+)/i;
            const match = message.match(budgetRegex);
            
            if (match && botMessage.toLowerCase().includes('set') && botMessage.toLowerCase().includes('budget')) {
              let category = match[1].toLowerCase().replace(/\s+/g, '_'); // Convert "wild cards" to "wild_cards"
              const amount = parseInt(match[2]);
              
              // Normalize category names
              if (category === 'wild_cards' || category === 'wild_card') category = 'wild_cards';
              if (category === 'nest_egg') category = 'nest_egg';
              
              console.log(`üîß DEBUG: Detected budget setting from text - ${category}: $${amount}`);
              
              try {
                // Call the actual budget setting function
                const result = await convexService.setBudget(
                  USE_TEST_USER ? TEST_USER_ID : null,
                  category,
                  amount,
                  `AI set budget for ${category} based on conversation`
                );
                console.log('üîß DEBUG: Budget set successfully via text parsing:', result);
                
                // Update the response message
                botMessage = `‚úÖ Perfect! I've set your ${category} budget to $${amount} per month. This budget will help you manage your ${category === 'foundations' ? 'essential expenses like rent and groceries' : category === 'delights' ? 'fun spending like dining and entertainment' : category === 'nest_egg' ? 'savings and investment goals' : 'emergency funds and unexpected expenses'}.`;
                
              } catch (error) {
                console.error('üîß DEBUG: Budget setting error via text parsing:', error);
                botMessage += '\n\n‚ö†Ô∏è Note: I understand you want to set a budget, but there was an issue saving it. Please try again.';
              }
            }
          }
          
        } else if (response.text && typeof response.text === 'function') {
          botMessage = response.text();
        } else if (typeof response.text === 'string') {
          botMessage = response.text;
        } else {
          botMessage = JSON.stringify(response);
        }
      }
      
      console.log('üîß DEBUG: Response text extracted successfully:', botMessage.substring(0, 100));
      console.log('üîß DEBUG: Message content for categorization check:', message);
      
      // TRANSACTION CATEGORIZATION: Add automatic categorization for transaction-related messages (simple case)
      const shouldCategorize = message.toLowerCase().includes('categor') || 
                              message.toLowerCase().includes('tx_') ||
                              message.toLowerCase().includes('transaction');
      
      console.log('üîß DEBUG: Should categorize check:', shouldCategorize);
      console.log('üîß DEBUG: Contains categor:', message.toLowerCase().includes('categor'));
      console.log('üîß DEBUG: Contains tx_:', message.toLowerCase().includes('tx_'));
      console.log('üîß DEBUG: Contains transaction:', message.toLowerCase().includes('transaction'));
      
      if (shouldCategorize) {
        console.log('üîß DEBUG: Auto-generating function calls for transaction categorization (simple case)');
        
        // Extract transaction IDs from the message
        const txIdPattern = /tx_(\w+)/g;
        let txMatch;
        const autoFunctionCalls = [];
        
        while ((txMatch = txIdPattern.exec(message)) !== null) {
          const txId = `tx_${txMatch[1]}`;
          
          // Determine category based on transaction context
          let suggestion = 'wild_cards';
          let confidence = 0.6;
          
          const lowerMessage = message.toLowerCase();
          if (lowerMessage.includes('starbucks') || lowerMessage.includes('coffee') || 
              lowerMessage.includes('netflix') || lowerMessage.includes('entertainment')) {
            suggestion = 'delights';
            confidence = 0.8;
          } else if (lowerMessage.includes('rent') || lowerMessage.includes('mortgage') || 
                    lowerMessage.includes('grocery') || lowerMessage.includes('gas')) {
            suggestion = 'foundations';
            confidence = 0.9;
          }
          
          autoFunctionCalls.push({ name: 'suggestCategory', args: { txId, suggestion, confidence } });
          
          // Execute the function call
          try {
            console.log(`üîß DEBUG: Auto-executing suggestCategory - ${txId}: ${suggestion} (${confidence})`);
            await convexService.suggestCategory(txId, suggestion, confidence);
            console.log('üîß DEBUG: Category suggested successfully');
          } catch (error) {
            console.error(`üîß DEBUG: Error executing auto suggestCategory:`, error);
          }
        }
        
        if (autoFunctionCalls.length > 0) {
          botMessage += `\n\n<div class="transaction-categorization">
            <h4>‚úÖ Transaction Categorization Complete!</h4>
            <p>I've automatically analyzed and categorized ${autoFunctionCalls.length} transaction${autoFunctionCalls.length > 1 ? 's' : ''} for you:</p>
            <ul>`;
          autoFunctionCalls.forEach(call => {
            const { txId, suggestion, confidence } = call.args;
            botMessage += `<li><strong>${txId}:</strong> ${suggestion} (${Math.round(confidence * 100)}% confidence)</li>`;
          });
          botMessage += `</ul></div>`;
        }
      }
      
      // Response already handled in main chat endpoint above
      return res.json({
        message: botMessage,
        timestamp: new Date().toISOString(),
        hasFinancialData: !!accessToken
      });
      
    } catch (aiError) {
      console.error('üîß DEBUG: AI Error:', aiError);
      return res.json({
        message: "AI Error: " + aiError.message,
        timestamp: new Date().toISOString(),
        hasFinancialData: !!accessToken
      });
    }

    let financialContext = '';
    if (accessToken) {
      try {
        console.log('ü§ñ Fetching financial data for AI context...');
        const financialData = await getFinancialSummary(accessToken);
        
        financialContext = `
=== FINANCIAL CONTEXT FROM CONNECTED PLAID ACCOUNT (Last 30 days) ===

ACCOUNT BALANCES:
${financialData.balances.map(acc => `- ${acc.name} (${acc.type}): $${acc.balances.current || 'N/A'}`).join('\n')}

SUMMARY STATISTICS:
- Total Balance Across All Accounts: $${financialData.summary.totalBalance}
- Total Spending in Period: $${financialData.summary.monthlySpending}
- Number of Transactions Found: ${financialData.summary.transactionCount}

TOP SPENDING CATEGORIES (AI-powered custom categorization):
${financialData.summary.topCategories.length > 0 ? 
  financialData.summary.topCategories.map(cat => 
    `- ${cat.category}: $${cat.amount}\n${cat.subcategories.map(sub => `  ‚Ä¢ ${sub.subcategory}: $${sub.amount}`).join('\n')}`
  ).join('\n') : 
  '- No spending categories found in this period'}

TOP MERCHANTS (from actual transactions):
${financialData.summary.topMerchants.length > 0 ? 
  financialData.summary.topMerchants.map(merch => `- ${merch.merchant}: $${merch.amount}`).join('\n') : 
  '- No merchant data found in this period'}

ACTUAL RECENT TRANSACTIONS (up to 10 most recent with AI categorization and enrichment):
${financialData.recentTransactions.length > 0 ? 
  financialData.recentTransactions.map(t => {
    const merchantDisplay = t.enrichedMerchantName || t.merchantName || t.name;
    const enrichmentInfo = t.merchantLogo ? ' üè™' : '';
    return `- ${t.date}: ${merchantDisplay}${enrichmentInfo} - $${t.amount.toFixed(2)} [${t.customCategory}: ${t.customSubcategory}]`;
  }).join('\n') : 
  '- No transactions found in this period'}

=== END OF ACTUAL FINANCIAL DATA ===`;

        console.log('üß† FINANCIAL CONTEXT BEING SENT TO AI:');
        console.log('='.repeat(80));
        console.log(financialContext);
        console.log('='.repeat(80));
        
      } catch (error) {
        console.error('‚ùå Error fetching financial data:', error);
        financialContext = '\nNote: Unable to fetch current financial data for this conversation.';
      }
    }

    const systemPrompt = `
‚ú®  FINLEY ‚Äì Your Friendly Financial-Wellbeing Companion
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

1.  Mission & Personality
   ‚Ä¢ You are **Finley**, a warm, judgment-free guide who helps people make sense of their money.  
   ‚Ä¢ You speak in everyday language, encourage questions, and celebrate small wins.

2.  Non-Negotiable Data Guardrails
   1. Discuss only facts found in FINANCIAL CONTEXT **or** calculations derived from those facts (e.g., totals, averages, percentages).  
   2. Never fabricate, guess, or estimate balances, transactions, projections, or dates.  
   3. If the answer truly is not in the data (even after reasonable calculation), reply:  
      "I don't have that information from your connected account."  
   4. If FINANCIAL CONTEXT is empty, say:  
      "It looks like no bank account is connected yet."  
   5. Do not give personalised financial advice or product recommendations.  
   6. Never imply Google, Plaid, or any institution endorses Finley.

3.  What You *Can* Do
   ‚Ä¢ List or summarise the exact balances and transactions supplied.  
   ‚Ä¢ Compute clear arithmetic summaries (e.g., "Your total across all linked accounts is \$12 345.67").  
   ‚Ä¢ Compare periods that exist in the data (e.g., "Utilities were \$15 lower this month than last").  
   ‚Ä¢ Spot real patterns (categories, frequency, spikes) present in the data.  
   ‚Ä¢ Empathise and normalise emotions: "Money can feel stressful‚Äîasking is an important first step."  
   ‚Ä¢ Invite connection of further accounts or data when missing.

4.  What You *Cannot* Do
   ‚Ä¢ Guess future growth, interest, or returns.  
   ‚Ä¢ Reveal or misuse trademarks or confidential info.

5.  Tone & Interaction Hints
   ‚Ä¢ Natural-language mapping:  
        ‚Äì "How much money do I have?" ‚áí sum all current balances provided.  
        ‚Äì "Where am I overspending?" ‚áí highlight largest spending categories that exist.  
   ‚Ä¢ Gentle boundary: "I'd need data from your savings account before I can total everything."  

6.  Response Format Requirements:
   ‚Ä¢ **ALWAYS respond with valid HTML markup** for rich formatting and better readability
   ‚Ä¢ Use semantic HTML elements: <h3>, <h4>, <ul>, <ol>, <li>, <table>, <strong>, <em>, <p>, <div>
   ‚Ä¢ Use tables for financial data comparisons with <table>, <thead>, <tbody>, <tr>, <th>, <td>
   ‚Ä¢ Use lists for multiple items: <ul> for unordered, <ol> for ordered
   ‚Ä¢ Use <strong> for emphasis on amounts and important data
   ‚Ä¢ Use <em> for subtle emphasis and context
   ‚Ä¢ Use CSS classes for styling: 'amount' for money, 'positive' for gains, 'negative' for losses
   ‚Ä¢ Example: "<p>Your checking account has <strong class='amount'>$1,234.56</strong> available.</p>"
   ‚Ä¢ Example: "<h4>Recent Transactions:</h4><ul><li><strong>McDonald's:</strong> $12.50 on 2024-01-15</li></ul>"

7.  Chart Generation Capabilities - BE VISUAL WHENEVER POSSIBLE:
   ‚Ä¢ **ALWAYS generate charts for financial data when listing 3+ items** - users love visual insights!
   ‚Ä¢ **MANDATORY chart scenarios:**
     - Debt breakdown (any debt discussion) ‚Üí [CHART_REQUEST:{"type":"debt_breakdown","chartType":"auto"}]
     - Spending by category ‚Üí [CHART_REQUEST:{"type":"spending_breakdown","chartType":"auto"}] 
     - Account balances ‚Üí [CHART_REQUEST:{"type":"balance_overview","chartType":"auto"}]
     - Recent transactions (when showing spending patterns) ‚Üí [CHART_REQUEST:{"type":"transaction_breakdown","chartType":"auto"}]
     - Any subcategory analysis ‚Üí [CHART_REQUEST:{"type":"subcategory_breakdown","category":"CategoryName","chartType":"auto"}]
   
   ‚Ä¢ **Chart-first mentality**: If you're listing financial data, ask "would this be clearer as a chart?" (answer is usually YES)
   ‚Ä¢ **Perfect chart opportunities:**
     - "Here's your debt breakdown" ‚Üí ALWAYS include debt chart
     - "Your spending breakdown shows" ‚Üí ALWAYS include spending chart  
     - "Looking at your accounts" ‚Üí ALWAYS include balance chart
     - "Recent transactions include" ‚Üí ALWAYS include transaction chart
   
   ‚Ä¢ Available chart types: spending_breakdown, balance_overview, subcategory_breakdown, spending_analysis, debt_breakdown, transaction_breakdown
   ‚Ä¢ Charts enhance understanding and make financial data much more engaging - use them liberally!

7.  Budget Management Capabilities:
   ‚Ä¢ **Budget Conversation Handling**: You can help users set budgets through natural conversation
   ‚Ä¢ **Budget Categories**: Work with 4 categories - Foundations (üè†), Delights (‚ú®), Nest Egg (üê£), Wild Cards (üé≤)
   ‚Ä¢ **Budget Setting Protocol**: When users want to set budgets, make POST requests to these endpoints:
     - `/api/budget/set` with {category, budgetAmount, aiAnalysis}
     - `/api/budget/user` to retrieve existing budgets
   ‚Ä¢ **Budget Conversations**: Listen for phrases like:
     - "I want to set a budget for..."
     - "My monthly budget should be..."
     - "Help me budget..."
     - "I need $X for essentials/fun/savings/unexpected..."
   ‚Ä¢ **Response with Budget Actions**: When setting budgets, include this format:
     [BUDGET_ACTION:{"action":"set","category":"foundations","amount":2000,"analysis":"User specified $2000 for essential monthly expenses"}]
   ‚Ä¢ **Available Categories**:
     - foundations: Essential expenses like rent, utilities, groceries
     - delights: Fun and discretionary spending like dining out, entertainment
     - nest_egg: Savings and investments for future goals
     - wild_cards: Unexpected expenses and emergency fund

8.  Runtime Template (append at run-time):
   [System] You are Finley. Follow all guardrails above.  
   FINANCIAL CONTEXT:  
   ${financialContext}
`;
    let prompt = systemPrompt;
    if (conversationHistory.length > 0) {
      const historyText = conversationHistory
        .map(msg => `${msg.sender === 'user' ? 'User' : 'Assistant'}: ${msg.text}`)
        .join('\n');
      prompt += `\n\nPrevious conversation:\n${historyText}`;
    }
    prompt += `\n\nUser: ${message}\n\nAssistant:`;

    console.log('üìù COMPLETE PROMPT BEING SENT TO GEMINI:');
    console.log('='.repeat(100));
    console.log(prompt);
    console.log('='.repeat(100));

    console.log('üîß DEBUG: About to call getGenerativeModel...');
    const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });
    console.log('üîß DEBUG: Model created, about to call generateContent...');
    const response = await model.generateContent(prompt);
    console.log('üîß DEBUG: generateContent completed...');

    let botMessage = response.response.text();
    
    console.log('ü§ñ AI RESPONSE RECEIVED:');
    console.log('='.repeat(60));
    console.log(botMessage);
    console.log('='.repeat(60));

    // Validate response if financial data was provided
    if (accessToken && financialContext) {
      const hasSpecificNumbers = /\$[\d,]+\.?\d*/.test(botMessage);
      const hasPlaidData = financialContext.includes('FINANCIAL CONTEXT FROM CONNECTED PLAID ACCOUNT');
      
      if (hasSpecificNumbers && hasPlaidData) {
        console.log('‚ö†Ô∏è  VALIDATION: AI response contains financial numbers - checking against Plaid data...');
        
        // Extract financial numbers from the context and response for comparison
        const contextNumbers = financialContext.match(/\$[\d,]+\.?\d*/g) || [];
        const responseNumbers = botMessage.match(/\$[\d,]+\.?\d*/g) || [];
        
        console.log('üí∞ Numbers in Plaid data:', contextNumbers);
        console.log('üí¨ Numbers in AI response:', responseNumbers);
        
        // Smart validation: Allow calculated values that can be derived from source data
        const sourceValues = contextNumbers.map(num => parseFloat(num.replace(/[$,]/g, '')));
        const responseValues = responseNumbers.map(num => parseFloat(num.replace(/[$,]/g, '')));
        
        const hasUnknownNumbers = responseValues.some(responseVal => {
          // Check if the number exists in source data
          if (sourceValues.includes(responseVal)) {
            return false;
          }
          
          // Check if it could be a reasonable calculation (sum, difference, etc.)
          const tolerance = 10; // Allow for AI calculation variations and floating point precision
          
          // Check if it's a sum of any combination of source values
          for (let i = 1; i < Math.pow(2, sourceValues.length); i++) {
            let sum = 0;
            for (let j = 0; j < sourceValues.length; j++) {
              if (i & Math.pow(2, j)) {
                sum += sourceValues[j];
              }
            }
            if (Math.abs(sum - responseVal) < tolerance) {
              return false; // This is a valid calculation
            }
          }
          
          // Check if it's a difference between values
          for (let i = 0; i < sourceValues.length; i++) {
            for (let j = 0; j < sourceValues.length; j++) {
              if (i !== j && Math.abs(Math.abs(sourceValues[i] - sourceValues[j]) - responseVal) < tolerance) {
                return false; // This is a valid difference
              }
            }
          }
          
          // Check if it's a percentage or simple multiple (within reason)
          for (let sourceVal of sourceValues) {
            const ratio = responseVal / sourceVal;
            if (ratio > 0 && ratio <= 2.0 && Math.abs(ratio * sourceVal - responseVal) < tolerance) {
              return false; // This could be a percentage or simple calculation
            }
          }
          
          return true; // Cannot derive this number from source data
        });
        
        if (hasUnknownNumbers) {
          console.log('üö® WARNING: AI may be hallucinating financial data!');
          botMessage = "I apologize, but I can only discuss the specific financial information from your connected bank account. Let me provide accurate information based on your actual account data. " + 
                     "Please ask me about your account balances, recent transactions, or spending patterns, and I'll give you information based solely on your real banking data.";
        } else {
          console.log('‚úÖ VALIDATION: AI response uses only provided data or valid calculations');
        }
      }
    }

    // Process chart requests in the AI response
    let charts = [];
    if (accessToken && financialContext) {
      const chartRequestRegex = /\[CHART_REQUEST:({[^}]+})\]/g;
      let match;
      
      while ((match = chartRequestRegex.exec(botMessage)) !== null) {
        try {
          const chartRequest = JSON.parse(match[1]);
          console.log('üìä AI requested chart:', chartRequest);
          
          const financialData = await getFinancialSummary(accessToken);
          const chartData = generateChart(financialData, chartRequest);
          
          if (chartData) {
            charts.push(chartData);
            console.log('‚úÖ Generated chart:', chartData.id);
          }
        } catch (error) {
          console.error('‚ùå Error processing chart request:', error);
        }
      }
      
      // Remove chart request markers from the message
      botMessage = botMessage.replace(chartRequestRegex, '').trim();
    }

    // Process budget actions in the AI response
    const budgetActionRegex = /\[BUDGET_ACTION:({[^}]+})\]/g;
    let budgetMatch;
    
    while ((budgetMatch = budgetActionRegex.exec(botMessage)) !== null) {
      try {
        const budgetAction = JSON.parse(budgetMatch[1]);
        console.log('üí∞ AI requested budget action:', budgetAction);
        
        if (budgetAction.action === 'set' && budgetAction.category && budgetAction.amount) {
          const userId = 'test_user'; // In production, get from auth
          const result = await convexService.setBudget(
            userId,
            budgetAction.category,
            budgetAction.amount,
            budgetAction.analysis || 'AI-set budget'
          );
          
          console.log('‚úÖ Budget set successfully:', result);
          
          // Add confirmation to the message
          botMessage += `\n\n<div class="budget-confirmation">
            <h4>‚úÖ Budget Set Successfully!</h4>
            <p><strong>${budgetAction.category.charAt(0).toUpperCase() + budgetAction.category.slice(1)}:</strong> $${budgetAction.amount}/month</p>
          </div>`;
        }
      } catch (error) {
        console.error('‚ùå Error processing budget action:', error);
      }
    }
    
    // Remove budget action markers from the message
    botMessage = botMessage.replace(budgetActionRegex, '').trim();

    // TRANSACTION CATEGORIZATION: Add automatic categorization for transaction-related messages
    const shouldCategorize = message.toLowerCase().includes('categor') || 
                            message.toLowerCase().includes('tx_') ||
                            message.toLowerCase().includes('transaction');
    
    if (shouldCategorize) {
      console.log('üîß DEBUG: Auto-generating function calls for transaction categorization');
      
      // Extract transaction IDs from the message
      const txIdPattern = /tx_(\w+)/g;
      let txMatch;
      const autoFunctionCalls = [];
      
      while ((txMatch = txIdPattern.exec(message)) !== null) {
        const txId = `tx_${txMatch[1]}`;
        
        // Determine category based on transaction context
        let suggestion = 'wild_cards';
        let confidence = 0.6;
        
        const lowerMessage = message.toLowerCase();
        if (lowerMessage.includes('starbucks') || lowerMessage.includes('coffee') || 
            lowerMessage.includes('netflix') || lowerMessage.includes('entertainment')) {
          suggestion = 'delights';
          confidence = 0.8;
        } else if (lowerMessage.includes('rent') || lowerMessage.includes('mortgage') || 
                  lowerMessage.includes('grocery') || lowerMessage.includes('gas')) {
          suggestion = 'foundations';
          confidence = 0.9;
        }
        
        autoFunctionCalls.push({ name: 'suggestCategory', args: { txId, suggestion, confidence } });
        
        // Execute the function call
        try {
          console.log(`üîß DEBUG: Auto-executing suggestCategory - ${txId}: ${suggestion} (${confidence})`);
          await convexService.suggestCategory(txId, suggestion, confidence);
          console.log('üîß DEBUG: Category suggested successfully');
        } catch (error) {
          console.error(`üîß DEBUG: Error executing auto suggestCategory:`, error);
        }
      }
      
      if (autoFunctionCalls.length > 0) {
        botMessage += `\n\n<div class="transaction-categorization">
          <h4>‚úÖ Transaction Categorization Complete!</h4>
          <p>I've automatically analyzed and categorized ${autoFunctionCalls.length} transaction${autoFunctionCalls.length > 1 ? 's' : ''} for you:</p>
          <ul>`;
        autoFunctionCalls.forEach(call => {
          const { txId, suggestion, confidence } = call.args;
          botMessage += `<li><strong>${txId}:</strong> ${suggestion} (${Math.round(confidence * 100)}% confidence)</li>`;
        });
        botMessage += `</ul></div>`;
      }
    }

    res.json({
      message: botMessage,
      charts: charts,
      timestamp: new Date().toISOString(),
      hasFinancialData: !!accessToken
    });

  } catch (error) {
    console.error('Error generating response:', error);
    res.status(500).json({ 
      error: 'Failed to generate response',
      details: error.message 
    });
  }
});

// Voice Chat endpoint - Returns audio response from ElevenLabs
app.post('/api/voice-chat', async (req, res) => {
  try {
    const { message, conversationHistory = [], accessToken, voiceId } = req.body;

    if (!message) {
      return res.status(400).json({ error: 'Message is required' });
    }

    if (!process.env.CARTESIA_API_KEY) {
      return res.status(503).json({ 
        error: 'Voice chat not available',
        message: 'Cartesia API key not configured' 
      });
    }

    console.log('üéôÔ∏è Processing voice chat request...');
    console.log('üìù Message:', message);

    // Get AI response using the same logic as text chat
    let financialContext = '';
    if (accessToken) {
      try {
        console.log('ü§ñ Fetching financial data for voice AI context...');
        const financialData = await getFinancialSummary(accessToken);
        
        financialContext = `
=== FINANCIAL CONTEXT FROM CONNECTED PLAID ACCOUNT (Last 30 days) ===

ACCOUNT BALANCES:
${financialData.balances.map(acc => `- ${acc.name} (${acc.type}): $${acc.balances.current || 'N/A'}`).join('\n')}

SUMMARY STATISTICS:
- Total Balance Across All Accounts: $${financialData.summary.totalBalance}
- Total Spending in Period: $${financialData.summary.monthlySpending}
- Number of Transactions Found: ${financialData.summary.transactionCount}

TOP SPENDING CATEGORIES (AI-powered custom categorization):
${financialData.summary.topCategories.length > 0 ? 
  financialData.summary.topCategories.map(cat => 
    `- ${cat.category}: $${cat.amount}\n${cat.subcategories.map(sub => `  ‚Ä¢ ${sub.subcategory}: $${sub.amount}`).join('\n')}`
  ).join('\n') : 
  '- No spending categories found in this period'}

TOP MERCHANTS (from actual transactions):
${financialData.summary.topMerchants.length > 0 ? 
  financialData.summary.topMerchants.map(merch => `- ${merch.merchant}: $${merch.amount}`).join('\n') : 
  '- No merchant data found in this period'}

ACTUAL RECENT TRANSACTIONS (up to 10 most recent with AI categorization and enrichment):
${financialData.recentTransactions.length > 0 ? 
  financialData.recentTransactions.map(t => {
    const merchantDisplay = t.enrichedMerchantName || t.merchantName || t.name;
    const enrichmentInfo = t.merchantLogo ? ' üè™' : '';
    return `- ${t.date}: ${merchantDisplay}${enrichmentInfo} - $${t.amount.toFixed(2)} [${t.customCategory}: ${t.customSubcategory}]`;
  }).join('\n') : 
  '- No transactions found in this period'}

=== END OF ACTUAL FINANCIAL DATA ===`;
      } catch (error) {
        console.error('‚ùå Error fetching financial data for voice:', error);
        financialContext = '\nNote: Unable to fetch current financial data for this conversation.';
      }
    }

    // Modify system prompt for voice - shorter, more conversational responses
    const systemPrompt = `
‚ú®  FINLEY ‚Äì Voice Financial Assistant
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

You are Finley, a warm voice assistant helping with financial questions.

VOICE-SPECIFIC GUIDELINES:
‚Ä¢ Keep responses under 3 sentences for quick voice delivery
‚Ä¢ Use conversational, spoken language (avoid "bullet points" - say "first, second, third")
‚Ä¢ Speak numbers clearly: "$1,234.56" becomes "one thousand two hundred thirty four dollars and fifty six cents"
‚Ä¢ No HTML formatting - plain text only for voice synthesis
‚Ä¢ No charts in voice responses - describe data instead
‚Ä¢ Be warm and encouraging, like talking to a friend

DATA RULES (CRITICAL):
1. Only discuss facts from FINANCIAL CONTEXT or calculations from those facts
2. Never fabricate, guess, or estimate any financial data
3. If data isn't available, say "I don't have that information from your connected account"
4. No financial advice or product recommendations

TONE: Conversational, warm, and supportive - like a knowledgeable friend helping with money questions.

FINANCIAL CONTEXT:
${financialContext}`;

    let prompt = systemPrompt;
    if (conversationHistory.length > 0) {
      const historyText = conversationHistory
        .map(msg => `${msg.sender === 'user' ? 'User' : 'Assistant'}: ${msg.text}`)
        .join('\n');
      prompt += `\n\nPrevious conversation:\n${historyText}`;
    }
    prompt += `\n\nUser: ${message}\n\nAssistant:`;

    console.log('üìù Voice prompt length:', prompt.length);

    // Get AI response
    const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });
    const response = await model.generateContent(prompt);

    let botMessage = response.response.text();
    
    console.log('ü§ñ AI Voice Response:', botMessage);

    // Clean the response for voice synthesis
    const cleanTextForVoice = cleanTextForSpeech(botMessage);
    
    if (!cleanTextForVoice.trim()) {
      throw new Error('No speech content generated after cleaning');
    }

    // Convert to speech using ElevenLabs
    console.log('üîä Converting to speech...');
    const audioBuffer = await textToSpeech(cleanTextForVoice, voiceId);

    // Set appropriate headers for audio response
    res.set({
      'Content-Type': 'audio/wav',
      'Content-Length': audioBuffer.length,
      'Cache-Control': 'no-cache',
      'X-Original-Text': encodeURIComponent(botMessage), // Include original text in header
      'X-Clean-Text': encodeURIComponent(cleanTextForVoice) // Include cleaned text in header
    });

    console.log('‚úÖ Voice response ready, sending audio...');
    res.send(audioBuffer);

  } catch (error) {
    console.error('‚ùå Error in voice chat:', error);
    res.status(500).json({ 
      error: 'Voice chat failed',
      details: error.message 
    });
  }
});

// Stream voice chat endpoint for real-time audio streaming
app.post('/api/voice-chat/stream', async (req, res) => {
  try {
    const { message, conversationHistory = [], accessToken, voiceId } = req.body;

    if (!message) {
      return res.status(400).json({ error: 'Message is required' });
    }

    if (!process.env.CARTESIA_API_KEY) {
      return res.status(503).json({ 
        error: 'Voice streaming not available',
        message: 'Cartesia API key not configured' 
      });
    }

    console.log('üéµ Processing streaming voice chat request...');

    // Set headers for streaming
    res.setHeader('Content-Type', 'audio/mpeg');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');

    // Get AI response (same logic as above, simplified for brevity)
    // ... (AI processing logic similar to above)

    // For now, using the same non-streaming approach
    // In production, you'd want to implement true streaming
    const audioStream = await streamTextToSpeech(message, voiceId);
    
    audioStream.pipe(res);

  } catch (error) {
    console.error('‚ùå Error in streaming voice chat:', error);
    res.status(500).json({ 
      error: 'Voice streaming failed',
      details: error.message 
    });
  }
});

// ================================
// GEMINI LIVE API ENDPOINTS
// ================================

// Start a new Gemini Live session
app.post('/api/gemini-live/start-session', async (req, res) => {
  try {
    const { sessionId, userId, voiceName, systemPrompt } = req.body;
    
    if (!process.env.GOOGLE_AI_API_KEY) {
      return res.status(503).json({ 
        error: 'Gemini Live not available',
        message: 'Google AI API key not configured' 
      });
    }

    const sessionKey = sessionId || `session_${Date.now()}`;
    
    console.log('üé§ Starting Gemini Live session:', sessionKey);

    // Initialize Gemini Live Streaming service if not already done
    if (!geminiLiveStreaming.isConfigured()) {
      throw new Error('Gemini Live Streaming service not properly configured');
    }

    // Create custom session options
    const sessionOptions = {};
    
    if (voiceName) {
      sessionOptions.generationConfig = {
        responseModalities: ["AUDIO"],
        speechConfig: {
          voiceConfig: {
            prebuiltVoiceConfig: {
              voiceName: voiceName
            }
          }
        }
      };
    }

    if (systemPrompt) {
      sessionOptions.systemInstruction = {
        parts: [{ text: systemPrompt }]
      };
    }

    // Add financial tools for function calling
    const financialTools = [{
      functionDeclarations: [
        {
          name: "get_financial_summary",
          description: "Get user's financial summary including balances, spending, and recent transactions",
          parameters: {
            type: "object",
            properties: {
              accessToken: {
                type: "string",
                description: "Plaid access token for the user's connected account"
              },
              days: {
                type: "number",
                description: "Number of days to analyze (default: 30)",
                default: 30
              }
            },
            required: ["accessToken"]
          }
        },
        {
          name: "create_plaid_link_token",
          description: "Create a Plaid Link token for user to connect their bank account",
          parameters: {
            type: "object",
            properties: {
              userId: {
                type: "string",
                description: "User ID for the link token"
              }
            }
          }
        }
      ]
    }];

    sessionOptions.tools = financialTools;

    // Create a new streaming service instance for this session
    const sessionService = new GeminiLiveStreamingService();
    
    // Set up event handlers for the session
    sessionService.on('sessionStarted', (data) => {
      console.log('üì° Session started event:', sessionKey);
    });
    
    sessionService.on('responseReceived', (data) => {
      console.log('üì® Response received for session:', sessionKey);
      // Broadcast to connected clients via WebSocket if needed
    });
    
    sessionService.on('error', (error) => {
      console.error('‚ùå Session error:', sessionKey, error);
    });
    
    // Start the streaming session
    await sessionService.startStreamingSession(sessionOptions);
    
    // Store session reference
    geminiLiveSessions.set(sessionKey, {
      service: sessionService,
      userId: userId || 'default',
      startTime: Date.now(),
      lastActivity: Date.now()
    });

    console.log('‚úÖ Gemini Live session started successfully:', sessionKey);

    res.json({
      success: true,
      sessionId: sessionKey,
      status: sessionService.getStatus(),
      availableVoices: GeminiLiveStreamingService.getAvailableVoices()
    });

  } catch (error) {
    console.error('‚ùå Error starting Gemini Live session:', error);
    res.status(500).json({ 
      error: 'Failed to start Gemini Live session',
      details: error.message 
    });
  }
});

// Send audio to Gemini Live
app.post('/api/gemini-live/send-audio', upload.single('audio'), async (req, res) => {
  try {
    const { sessionId } = req.body;
    
    if (!sessionId || !geminiLiveSessions.has(sessionId)) {
      return res.status(400).json({ error: 'Invalid or expired session ID' });
    }

    if (!req.file) {
      return res.status(400).json({ error: 'Audio file is required' });
    }

    const session = geminiLiveSessions.get(sessionId);
    session.lastActivity = Date.now();

    console.log('üéµ Processing audio for Gemini Live session:', sessionId);
    console.log('üìä Audio size:', req.file.size, 'bytes');
    console.log('üìÅ Audio mimetype:', req.file.mimetype);
    console.log('üìÅ Audio buffer first 10 bytes:', req.file.buffer.slice(0, 10));

    // For streaming API, we need to handle responses via events
    // Set up a response handler for this request
    const responsePromise = new Promise((resolve, reject) => {
      const timeout = setTimeout(() => {
        reject(new Error('Response timeout'));
      }, 30000); // 30 second timeout

      const handleResponse = (data) => {
        clearTimeout(timeout);
        session.service.off('responseReceived', handleResponse);
        resolve(data);
      };

      session.service.on('responseReceived', handleResponse);
    });

    // Send audio to Gemini Live Streaming
    await session.service.sendAudioStream(req.file.buffer, {
      mimeType: req.file.mimetype || 'audio/wav'
    });

    // Wait for response
    try {
      const response = await responsePromise;

      // Handle function calls if present
      if (response && response.functionCalls && response.functionCalls.length > 0) {
        for (const functionCall of response.functionCalls) {
          const functionResult = await handleGeminiFunctionCall(functionCall, req);
          // Send function result back to Gemini
          await session.service.sendText(`Function ${functionCall.name} executed successfully. Result: ${JSON.stringify(functionResult)}`);
        }
      }

      // Return response to client
      if (response.audio) {
        // Convert base64 audio back to buffer
        const audioBuffer = Buffer.from(response.audio.data, 'base64');
        res.setHeader('Content-Type', response.audio.mimeType || 'audio/wav');
        res.send(audioBuffer);
      } else if (response.text) {
        res.json({
          success: true,
          text: response.text,
          hasAudio: false
        });
      } else {
        res.json({
          success: true,
          message: 'Audio processed successfully'
        });
      }
    } catch (timeoutError) {
      res.status(408).json({
        error: 'Response timeout',
        message: 'No response received within timeout period'
      });
    }

  } catch (error) {
    console.error('‚ùå Error processing audio with Gemini Live:', error);
    res.status(500).json({ 
      error: 'Audio processing failed',
      details: error.message 
    });
  }
});

// Send text to Gemini Live (for hybrid interactions)
app.post('/api/gemini-live/send-text', async (req, res) => {
  try {
    const { sessionId, message } = req.body;
    
    if (!sessionId || !geminiLiveSessions.has(sessionId)) {
      return res.status(400).json({ error: 'Invalid or expired session ID' });
    }

    if (!message) {
      return res.status(400).json({ error: 'Message is required' });
    }

    const session = geminiLiveSessions.get(sessionId);
    session.lastActivity = Date.now();

    console.log('üí¨ Processing text for Gemini Live session:', sessionId);

    const response = await session.service.sendText(message);

    // Handle function calls if present
    if (response && response.functionCalls && response.functionCalls.length > 0) {
      for (const functionCall of response.functionCalls) {
        const functionResult = await handleGeminiFunctionCall(functionCall, req);
        // Send function result back to Gemini
        await session.service.sendText(`Function ${functionCall.name} executed successfully. Result: ${JSON.stringify(functionResult)}`);
      }
    }

    // Return response
    if (response.audio) {
      const audioBuffer = Buffer.from(response.audio.data, 'base64');
      res.setHeader('Content-Type', response.audio.mimeType || 'audio/wav');
      res.send(audioBuffer);
    } else {
      res.json({
        success: true,
        text: response.text || 'Message processed successfully',
        hasAudio: !!response.audio
      });
    }

  } catch (error) {
    console.error('‚ùå Error processing text with Gemini Live:', error);
    res.status(500).json({ 
      error: 'Text processing failed',
      details: error.message 
    });
  }
});

// End Gemini Live session
app.post('/api/gemini-live/end-session', async (req, res) => {
  try {
    const { sessionId } = req.body;
    
    if (!sessionId || !geminiLiveSessions.has(sessionId)) {
      return res.status(400).json({ error: 'Invalid session ID' });
    }

    const session = geminiLiveSessions.get(sessionId);
    await session.service.endSession();
    geminiLiveSessions.delete(sessionId);

    console.log('‚úÖ Gemini Live session ended:', sessionId);

    res.json({
      success: true,
      message: 'Session ended successfully'
    });

  } catch (error) {
    console.error('‚ùå Error ending Gemini Live session:', error);
    res.status(500).json({ 
      error: 'Failed to end session',
      details: error.message 
    });
  }
});

// Get session status
app.get('/api/gemini-live/status/:sessionId?', async (req, res) => {
  try {
    const { sessionId } = req.params;

    if (sessionId) {
      // Get specific session status
      if (!geminiLiveSessions.has(sessionId)) {
        return res.status(404).json({ error: 'Session not found' });
      }

      const session = geminiLiveSessions.get(sessionId);
      res.json({
        sessionId,
        status: session.service.getStatus(),
        userId: session.userId,
        startTime: session.startTime,
        lastActivity: session.lastActivity,
        isActive: Date.now() - session.lastActivity < 5 * 60 * 1000 // 5 minutes
      });
    } else {
      // Get overall service status
      res.json({
        serviceStatus: geminiLiveStreaming.getStatus(),
        activeSessions: geminiLiveSessions.size,
        availableVoices: GeminiLiveStreamingService.getAvailableVoices(),
        isConfigured: geminiLiveStreaming.isConfigured()
      });
    }

  } catch (error) {
    console.error('‚ùå Error getting Gemini Live status:', error);
    res.status(500).json({ 
      error: 'Failed to get status',
      details: error.message 
    });
  }
});

// Helper function to handle Gemini function calls
async function handleGeminiFunctionCall(functionCall, req) {
  try {
    const { name, args } = functionCall;

    switch (name) {
      case 'get_financial_summary':
        console.log('üìä Executing get_financial_summary function');
        return await getFinancialSummary(args.accessToken, args.days || 30);

      case 'create_plaid_link_token':
        console.log('üîó Executing create_plaid_link_token function');
        const request = {
          user: {
            client_user_id: args.userId || 'user-id-' + Date.now(),
          },
          client_name: 'Financial Insights Chatbot',
          products: ['transactions'],
          country_codes: ['US'],
          language: 'en',
          webhook: 'https://webhook.site/unique-url', // Webhook endpoint for transaction updates
        };
        const response = await plaidClient.linkTokenCreate(request);
        return { link_token: response.data.link_token };

      default:
        throw new Error(`Unknown function: ${name}`);
    }
  } catch (error) {
    console.error('‚ùå Error executing function:', error);
    throw error;
  }
}

// Cleanup inactive sessions (run every 10 minutes)
setInterval(() => {
  const now = Date.now();
  const timeoutThreshold = 15 * 60 * 1000; // 15 minutes

  for (const [sessionId, session] of geminiLiveSessions.entries()) {
    if (now - session.lastActivity > timeoutThreshold) {
      console.log('üßπ Cleaning up inactive Gemini Live session:', sessionId);
      session.service.endSession().catch(console.error);
      geminiLiveSessions.delete(sessionId);
    }
  }
}, 10 * 60 * 1000);

// ================================
// END GEMINI LIVE API ENDPOINTS  
// ================================

// Plaid API endpoints
app.post('/api/plaid/create-link-token', async (req, res) => {
  try {
    console.log('Creating link token...');
    
    if (!process.env.PLAID_CLIENT_ID || !process.env.PLAID_SECRET) {
      throw new Error('Plaid credentials not configured. Please check PLAID_CLIENT_ID and PLAID_SECRET in your .env file.');
    }

    const request = {
      user: {
        client_user_id: 'user-id-' + Date.now(), // In production, use actual user ID
      },
      client_name: 'Financial Insights Chatbot',
      products: ['transactions'],
      country_codes: ['US'],
      language: 'en',
      webhook: 'https://webhook.site/unique-url', // Required for transactions product in sandbox
    };

    console.log('Plaid request:', { ...request, user: { client_user_id: 'user-id-xxxxx' } });
    
    const response = await plaidClient.linkTokenCreate(request);
    console.log('Link token created successfully');
    
    res.json({ link_token: response.data.link_token });
  } catch (error) {
    console.error('Error creating link token:', error);
    console.error('Error details:', {
      message: error.message,
      status: error.status,
      code: error.error_code,
      type: error.error_type
    });
    
    res.status(500).json({ 
      error: 'Failed to create link token',
      details: error.message || 'Unknown error occurred'
    });
  }
});

app.post('/api/plaid/exchange-public-token', async (req, res) => {
  try {
    const { public_token } = req.body;
    
    if (!public_token) {
      return res.status(400).json({ error: 'Public token is required' });
    }

    const response = await plaidClient.itemPublicTokenExchange({
      public_token: public_token,
    });

    const accessToken = response.data.access_token;
    const itemId = response.data.item_id;

    // Store access token for webhook processing
    console.log('üíæ Storing access token for webhook-based transaction sync...');
    
    try {
      const userId = USE_TEST_USER ? TEST_USER_ID : 'default_user';
      
      // Update account balance in Convex with the access token
      const { getAccountBalances } = require('./plaidClient');
      const balances = await getAccountBalances(accessToken);
      const totalBalance = balances.reduce((sum, account) => sum + (account.balances.current || 0), 0);
      
      await convexService.updateAccountBalance(userId, totalBalance, accessToken);
      console.log(`‚úÖ Updated account balance: $${totalBalance.toFixed(2)} and stored access token`);
      console.log(`‚è≥ Waiting for Plaid webhook to notify when transactions are ready...`);
      
    } catch (syncError) {
      console.error('‚ùå Error during initial setup:', syncError);
      // Don't fail the token exchange if this fails - just log the error
    }

    // In production, store these tokens securely in your database
    res.json({ 
      access_token: accessToken,
      item_id: itemId,
      success: true,
      transactions_synced: true
    });
  } catch (error) {
    console.error('Error exchanging public token:', error);
    res.status(500).json({ 
      error: 'Failed to exchange public token',
      details: error.message 
    });
  }
});

app.post('/api/plaid/financial-summary', async (req, res) => {
  try {
    const { accessToken } = req.body;
    
    if (!accessToken) {
      return res.status(400).json({ error: 'Access token is required' });
    }

    const financialData = await getFinancialSummary(accessToken);
    res.json(financialData);
  } catch (error) {
    console.error('Error fetching financial summary:', error);
    res.status(500).json({ 
      error: 'Failed to fetch financial data',
      details: error.message 
    });
  }
});

// Plaid webhook endpoint
app.post('/api/plaid/webhook', async (req, res) => {
  try {
    const { webhook_type, webhook_code, item_id, new_transactions, removed_transactions } = req.body;
    
    console.log(`ü™ù Plaid webhook received: ${webhook_type}.${webhook_code} for item ${item_id}`);
    
    // Respond immediately to Plaid (must be within 10 seconds)
    res.status(200).json({ acknowledged: true });
    
    // Handle webhook asynchronously 
    if (webhook_type === 'TRANSACTIONS') {
      if (webhook_code === 'SYNC_UPDATES_AVAILABLE') {
        console.log('üìä Transaction updates available, syncing to Convex...');
        await handleTransactionSync(item_id);
      } else if (webhook_code === 'INITIAL_UPDATE') {
        console.log('üÜï Initial transaction data ready');
        await handleTransactionSync(item_id);
      } else if (webhook_code === 'HISTORICAL_UPDATE') {
        console.log('üìö Historical transaction data ready');
        await handleTransactionSync(item_id);
      }
    }
    
  } catch (error) {
    console.error('‚ùå Webhook error:', error);
    // Still return 200 to Plaid to prevent retries
    res.status(200).json({ acknowledged: false, error: error.message });
  }
});

// Handle transaction sync using modern /transactions/sync API
async function handleTransactionSync(itemId) {
  try {
    console.log(`üîÑ Starting transaction sync for item ${itemId}`);
    
    // TODO: Get access token from database using itemId
    // For now, we'll need to modify this to store/retrieve tokens properly
    const userId = USE_TEST_USER ? TEST_USER_ID : 'default_user';
    
    // Get the access token from Convex (stored in updateAccountBalance)
    const userAccount = await convexService.getUserAccount(userId);
    if (!userAccount?.plaidAccessToken) {
      console.error('‚ùå No access token found for transaction sync');
      return;
    }
    
    const accessToken = userAccount.plaidAccessToken;
    
    // Use modern /transactions/sync endpoint
    let cursor = ''; // Start from beginning for full sync
    let hasMore = true;
    let totalSynced = 0;
    
    while (hasMore) {
      console.log(`üì• Fetching transactions with cursor: ${cursor || 'initial'}`);
      
      const syncResponse = await plaidClient.transactionsSync({
        access_token: accessToken,
        cursor: cursor,
        count: 100 // Max transactions per request
      });
      
      const { added, modified, removed, has_more, next_cursor } = syncResponse.data;
      
      console.log(`üìä Sync batch: +${added.length} added, ~${modified.length} modified, -${removed.length} removed`);
      
      // Process added transactions
      for (const transaction of added) {
        try {
          const transactionData = {
            userId,
            txId: transaction.transaction_id,
            plaidTransactionId: transaction.transaction_id,
            accountId: transaction.account_id,
            amount: transaction.amount,
            date: Date.parse(transaction.date),
            merchantName: transaction.merchant_name || transaction.name,
            description: transaction.name,
            plaidCategory: transaction.category,
            plaidSubcategory: transaction.personal_finance_category?.primary || null,
            currencyCode: transaction.iso_currency_code || 'USD',
            createdAt: Date.now(),
            isApproved: false
          };
          
          await convexService.storeTransaction(transactionData);
          totalSynced++;
        } catch (storeError) {
          console.error(`‚ùå Error storing transaction ${transaction.transaction_id}:`, storeError.message);
        }
      }
      
      // TODO: Handle modified and removed transactions
      
      cursor = next_cursor;
      hasMore = has_more;
    }
    
    console.log(`‚úÖ Transaction sync completed: ${totalSynced} transactions synced to Convex`);
    
  } catch (error) {
    console.error('‚ùå Transaction sync failed:', error);
  }
}

// Get transaction category breakdown
app.get('/api/categories/:accessToken', async (req, res) => {
  try {
    const { accessToken } = req.params;
    
    if (!accessToken) {
      return res.status(400).json({ error: 'Access token is required' });
    }

    const financialData = await getFinancialSummary(accessToken);
    
    res.json({
      categoryBreakdown: financialData.summary.topCategories,
      totalSpending: financialData.summary.monthlySpending,
      transactionCount: financialData.summary.transactionCount
    });

  } catch (error) {
    console.error('Error fetching category data:', error);
    res.status(500).json({ 
      error: 'Failed to fetch category data',
      details: error.message 
    });
  }
});

app.get('/api/health', (req, res) => {
  res.json({ 
    status: 'healthy', 
    timestamp: new Date().toISOString(),
    model: 'gemini-2.0-flash-exp',
    plaidConfigured: !!(process.env.PLAID_CLIENT_ID && process.env.PLAID_SECRET),
    voiceChatEnabled: !!process.env.CARTESIA_API_KEY,
    dailyConfigured: !!(process.env.DAILY_API_KEY && process.env.DAILY_API_KEY !== 'your-daily-api-key-here'),
    sttEnabled: !!process.env.OPENAI_API_KEY,
    convexConfigured: !!process.env.CONVEX_URL
  });
});

// ===== CONVEX BUDGET API ROUTES =====

// Get user budgets
app.post('/api/convex/budgets', async (req, res) => {
  try {
    console.log('üîß DEBUG: /api/convex/budgets called with:', req.body);
    const { function: functionName, args } = req.body || {};
    
    let result;
    switch (functionName) {
      case 'getUserBudgets':
        result = await convexService.getUserBudgets(args.userId);
        break;
      case 'getUserAccount':
        result = await convexService.getUserAccount(args.userId);
        break;
      case 'getSpendingSummary':
        result = await convexService.getSpendingSummary(args.userId);
        break;
      default:
        return res.status(400).json({ error: 'Unknown function' });
    }
    
    res.json({ success: true, result });
  } catch (error) {
    console.error('Convex query error:', error);
    res.status(500).json({ 
      error: 'Failed to execute Convex query',
      details: error.message 
    });
  }
});

// Set budget (called by AI)
app.post('/api/budget/set', async (req, res) => {
  try {
    const { userId = USE_TEST_USER ? TEST_USER_ID : null, category, budgetAmount, aiAnalysis } = req.body;
    
    if (!category || !budgetAmount) {
      return res.status(400).json({ error: 'Category and budget amount are required' });
    }

    const validCategories = ['foundations', 'delights', 'nest_egg', 'wild_cards'];
    if (!validCategories.includes(category)) {
      return res.status(400).json({ error: 'Invalid category' });
    }

    const result = await convexService.setBudget(userId, category, budgetAmount, aiAnalysis);
    
    // Recalculate feels like amount after setting budget
    await convexService.calculateFeelsLike(userId, category);
    
    res.json({ 
      success: true, 
      budgetId: result,
      message: `Budget set for ${category}: $${budgetAmount}`
    });
  } catch (error) {
    console.error('Error setting budget:', error);
    res.status(500).json({ 
      error: 'Failed to set budget',
      details: error.message 
    });
  }
});

// ===== CONVERSATIONAL BUDGETING API ROUTES =====

// Sync Plaid transactions
app.post('/api/syncPlaid', async (req, res) => {
  try {
    const { userId = USE_TEST_USER ? TEST_USER_ID : null } = req.body;
    
    if (!userId) {
      return res.status(400).json({ error: 'User ID is required' });
    }

    const result = await convexService.syncPlaid(userId);
    
    res.json({ 
      success: true, 
      newCount: result.newCount || 0,
      message: `Synced ${result.newCount || 0} new transactions`
    });
  } catch (error) {
    console.error('Error syncing Plaid:', error);
    res.status(500).json({ 
      error: 'Failed to sync Plaid transactions',
      details: error.message 
    });
  }
});

// AI suggest category for transaction
app.post('/api/transaction/suggest', async (req, res) => {
  try {
    const { txId, suggestion, confidence } = req.body;
    
    if (!txId || !suggestion || confidence === undefined) {
      return res.status(400).json({ error: 'Transaction ID, suggestion, and confidence are required' });
    }

    const result = await convexService.suggestCategory(txId, suggestion, confidence);
    
    res.json({ 
      success: true, 
      result,
      message: `Suggested ${suggestion} for transaction with ${confidence} confidence`
    });
  } catch (error) {
    console.error('Error suggesting category:', error);
    res.status(500).json({ 
      error: 'Failed to suggest category',
      details: error.message 
    });
  }
});

// Approve transaction category
app.post('/api/transaction/approve', async (req, res) => {
  try {
    const { txId, finalCategory } = req.body;
    
    if (!txId || !finalCategory) {
      return res.status(400).json({ error: 'Transaction ID and final category are required' });
    }

    const validCategories = ['foundations', 'delights', 'nest_egg', 'wild_cards'];
    if (!validCategories.includes(finalCategory)) {
      return res.status(400).json({ error: 'Invalid category' });
    }

    const result = await convexService.approveCategory(txId, finalCategory);
    
    res.json({ 
      success: true, 
      result,
      message: `Approved ${finalCategory} for transaction`
    });
  } catch (error) {
    console.error('Error approving category:', error);
    res.status(500).json({ 
      error: 'Failed to approve category',
      details: error.message 
    });
  }
});

// List transactions with filtering
app.post('/api/transactions/list', async (req, res) => {
  try {
    const { userId = USE_TEST_USER ? TEST_USER_ID : null, budgetId, from, to } = req.body;
    
    if (!userId) {
      return res.status(400).json({ error: 'User ID is required' });
    }

    const transactions = await convexService.listTransactions(userId, budgetId, from, to);
    
    res.json({ 
      success: true, 
      transactions,
      count: transactions.length
    });
  } catch (error) {
    console.error('Error listing transactions:', error);
    res.status(500).json({ 
      error: 'Failed to list transactions',
      details: error.message 
    });
  }
});

// Get uncategorized transactions for review
app.post('/api/transactions/uncategorized', async (req, res) => {
  try {
    const { userId = USE_TEST_USER ? TEST_USER_ID : null } = req.body;
    
    if (!userId) {
      return res.status(400).json({ error: 'User ID is required' });
    }

    const transactions = await convexService.getUncategorizedTransactions(userId);
    
    res.json({ 
      success: true, 
      transactions,
      count: transactions.length
    });
  } catch (error) {
    console.error('Error fetching uncategorized transactions:', error);
    res.status(500).json({ 
      error: 'Failed to fetch uncategorized transactions',
      details: error.message 
    });
  }
});

// Test endpoint for function calling
app.post('/api/test-functions', async (req, res) => {
  try {
    console.log('üß™ Testing function calling...');
    
    const tools = [{
      functionDeclarations: [{
        name: "suggestCategory",
        description: "Suggest a budget category for a transaction",
        parameters: {
          type: Type.OBJECT,
          properties: {
            txId: { type: Type.STRING, description: "Transaction ID" },
            suggestion: { 
              type: Type.STRING, 
              enum: ["foundations", "delights", "nest_egg", "wild_cards"],
              description: "Suggested category" 
            },
            confidence: { type: Type.NUMBER, description: "Confidence 0.0-1.0" }
          },
          required: ["txId", "suggestion", "confidence"]
        }
      }]
    }];

    const model = genAI.getGenerativeModel({ 
      model: 'gemini-2.0-flash-exp',
      tools: tools,
      toolConfig: { functionCallingConfig: { mode: 'ANY' } }
    });

    const prompt = `Categorize this transaction: tx_123 - Starbucks $4.50. Use the suggestCategory function.`;
    const response = await model.generateContent(prompt);

    console.log('üß™ Test response keys:', Object.keys(response));
    const candidate = response.candidates?.[0];
    
    let functionCalls = [];
    if (candidate?.content?.parts) {
      functionCalls = candidate.content.parts.filter(part => part.functionCall);
    }

    res.json({
      success: true,
      functionCallsFound: functionCalls.length,
      functionCalls: functionCalls,
      candidateText: candidate?.content?.parts?.[0]?.text || 'No text'
    });

  } catch (error) {
    console.error('üß™ Test error:', error);
    res.status(500).json({ error: error.message });
  }
});

// Daily.co API endpoints
const dailyService = new DailyService();

// Create a Daily.co room for voice chat
app.post('/api/daily/create-room', async (req, res) => {
  try {
    const { roomName } = req.body;
    
    console.log('üè† Creating Daily.co room...');
    const room = await dailyService.createRoom(roomName);
    
    res.json({
      success: true,
      room: room,
      configured: dailyService.isConfigured()
    });
  } catch (error) {
    console.error('‚ùå Error creating Daily.co room:', error);
    res.status(500).json({ 
      success: false, 
      error: error.message 
    });
  }
});

// Create a meeting token for authenticated access
app.post('/api/daily/create-token', async (req, res) => {
  try {
    const { roomName, userName, options = {} } = req.body;
    
    if (!roomName) {
      return res.status(400).json({ error: 'Room name is required' });
    }

    console.log('üé´ Creating Daily.co meeting token...');
    const token = await dailyService.createMeetingToken(roomName, {
      userName: userName || 'Voice Chat User',
      ...options
    });
    
    if (!token) {
      return res.status(503).json({ 
        error: 'Token creation not available',
        message: 'Daily.co API key not configured'
      });
    }

    res.json({
      success: true,
      token: token
    });

  } catch (error) {
    console.error('‚ùå Error creating Daily.co token:', error);
    res.status(500).json({ 
      error: 'Failed to create Daily.co token',
      details: error.message 
    });
  }
});

// Get room information
app.get('/api/daily/room/:roomName', async (req, res) => {
  try {
    const { roomName } = req.params;
    
    console.log('üìç Getting Daily.co room info...');
    const roomInfo = await dailyService.getRoomInfo(roomName);
    
    if (!roomInfo) {
      return res.status(404).json({ 
        error: 'Room not found or Daily.co not configured' 
      });
    }

    res.json({
      success: true,
      room: roomInfo
    });

  } catch (error) {
    console.error('‚ùå Error getting Daily.co room info:', error);
    res.status(500).json({ 
      error: 'Failed to get room info',
      details: error.message 
    });
  }
});

// Delete a room (cleanup)
app.delete('/api/daily/room/:roomName', async (req, res) => {
  try {
    const { roomName } = req.params;
    
    console.log('üóëÔ∏è Deleting Daily.co room...');
    const deleted = await dailyService.deleteRoom(roomName);
    
    res.json({
      success: deleted,
      message: deleted ? 'Room deleted successfully' : 'Room deletion failed or not configured'
    });

  } catch (error) {
    console.error('‚ùå Error deleting Daily.co room:', error);
    res.status(500).json({ 
      error: 'Failed to delete room',
      details: error.message 
    });
  }
});

// Speech-to-Text endpoint for audio streaming
app.post('/api/speech-to-text', upload.single('audio'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'No audio file provided' });
    }

    console.log('üé§ Processing audio chunk for STT:', req.file.size, 'bytes');
    
    // Check if we have Google AI API key for STT
    if (!process.env.GOOGLE_AI_API_KEY) {
      console.warn('‚ö†Ô∏è No Google AI API key available for STT');
      return res.status(503).json({ 
        error: 'Speech-to-text service not configured',
        transcript: '',
        is_final: false
      });
    }

    // Process audio for Speech-to-Text
    const transcript = await processAudioForSTT(req.file.buffer, req.body.format || 'webm');
    
    res.json({
      transcript: transcript,
      is_final: transcript.length > 0, // Simple heuristic
      confidence: 0.9 // Placeholder
    });

  } catch (error) {
    console.error('‚ùå Error processing STT:', error);
    res.status(500).json({ 
      error: error.message,
      transcript: '',
      is_final: false
    });
  }
});

// Process audio for Speech-to-Text
async function processAudioForSTT(audioBuffer, format) {
  try {
    // Validate audio buffer
    if (!audioBuffer || !Buffer.isBuffer(audioBuffer)) {
      console.log('üîá Invalid audio buffer provided');
      return '';
    }
    
    // Check if audio buffer is large enough to process
    if (audioBuffer.length < 1000) {
      console.log('üîá Audio chunk too small, skipping STT');
      return '';
    }
    
    // Check for suspiciously large buffers that might indicate feedback
    if (audioBuffer.length > 10 * 1024 * 1024) { // 10MB limit
      console.log('üîá Audio chunk too large, possible feedback loop detected');
      return '';
    }
    
    console.log('üß† Processing audio with OpenAI Whisper...');
    console.log('üìÅ Audio format received:', format, 'Buffer size:', audioBuffer.length);
    
    // Create a temporary file for OpenAI API
    const fs = require('fs');
    const path = require('path');
    const os = require('os');
    
    // Determine file extension based on the provided format parameter and buffer content
    let fileExtension = 'webm'; // Default to webm since that's what browsers typically send
    let actualFormat = format || 'webm';
    
    // Check the format parameter first
    if (format) {
      if (format.includes('wav')) {
        fileExtension = 'wav';
        actualFormat = 'wav';
      } else if (format.includes('webm')) {
        fileExtension = 'webm';
        actualFormat = 'webm';
      } else if (format.includes('mp3')) {
        fileExtension = 'mp3';
        actualFormat = 'mp3';
      } else if (format.includes('m4a')) {
        fileExtension = 'm4a';
        actualFormat = 'm4a';
      } else if (format.includes('flac')) {
        fileExtension = 'flac';
        actualFormat = 'flac';
      } else if (format.includes('ogg')) {
        fileExtension = 'ogg';
        actualFormat = 'ogg';
      }
    }
    
    // Additional buffer inspection for more accurate detection
    const firstBytes = audioBuffer.slice(0, 16);
    const header = firstBytes.toString('hex');
    
    if (header.startsWith('52494646') && header.includes('57415645')) {
      fileExtension = 'wav';
      actualFormat = 'wav';
      console.log('üîç Detected WAV format from buffer header');
    } else if (header.startsWith('1a45dfa3')) {
      fileExtension = 'webm';
      actualFormat = 'webm';
      console.log('üîç Detected WebM format from buffer header');
    } else if (header.startsWith('fffb') || header.startsWith('fff3')) {
      fileExtension = 'mp3';
      actualFormat = 'mp3';
      console.log('üîç Detected MP3 format from buffer header');
    } else if (header.startsWith('4f676753')) {
      fileExtension = 'ogg';
      actualFormat = 'ogg';
      console.log('üîç Detected OGG format from buffer header');
    } else {
      // If we can't detect, assume it's webm since that's most common from browsers
      console.log('üîç Could not detect format from header, assuming WebM');
      fileExtension = 'webm';
      actualFormat = 'webm';
    }
    
    console.log('üîç Final format decision:', actualFormat, 'Extension:', fileExtension);
    
    const tempDir = os.tmpdir();
    const tempFileName = `audio_${Date.now()}_${Math.random().toString(36).substr(2, 9)}.${fileExtension}`;
    const tempFilePath = path.join(tempDir, tempFileName);
    
    try {
      // Write audio buffer to temporary file
      fs.writeFileSync(tempFilePath, audioBuffer);
      
      // Verify file was created and has content
      const stats = fs.statSync(tempFilePath);
      console.log(`üìÅ Created temp file: ${tempFileName} (${stats.size} bytes)`);
      
      // Verify the file is readable
      if (stats.size === 0) {
        throw new Error('Created audio file is empty');
      }
      
      // Create a file stream for OpenAI API
      const audioFile = fs.createReadStream(tempFilePath);
      
      // Use OpenAI Whisper for transcription
      const transcription = await openai.audio.transcriptions.create({
        file: audioFile,
        model: 'whisper-1', // Latest available model
        language: 'en',
        response_format: 'text',
        temperature: 0.0,
        prompt: "This is a clear conversation about personal finance, banking, and money management."
      });
      
      const transcript = transcription.trim();
      console.log('‚úÖ Whisper transcription result:', transcript);
      
      // Clean up successful temp file
      try {
        if (fs.existsSync(tempFilePath)) {
          fs.unlinkSync(tempFilePath);
          console.log('üóëÔ∏è Cleaned up temp file');
        }
      } catch (cleanupError) {
        console.warn('‚ö†Ô∏è Could not clean up temp file:', cleanupError.message);
      }
      
      return transcript;
      
    } catch (fileError) {
      // Clean up failed temp file
      try {
        if (fs.existsSync(tempFilePath)) {
          fs.unlinkSync(tempFilePath);
        }
      } catch (cleanupError) {
        // Ignore cleanup errors
      }
      
      console.error(`‚ùå Failed to process ${fileExtension} file:`, fileError.message);
      
      // Enhanced error logging and format conversion attempt
      if (fileError.message.includes('Invalid file format') || fileError.message.includes('could not be decoded') || fileError.message.includes('format is not supported')) {
        console.warn('‚ö†Ô∏è OpenAI API bad request - audio format issue');
        console.warn('üìù Error details:', fileError.message);
        console.warn('üí° Browser may be sending incompatible WebM encoding');
        console.warn('üìù File extension tried:', fileExtension);
        console.warn('üìù Format parameter:', format);
        console.warn('üìù Buffer size:', audioBuffer.length);
        console.warn('üìù Buffer header (hex):', audioBuffer.slice(0, 16).toString('hex'));
        
        // If it's a WebM format issue, suggest the client use a different format
        if (actualFormat === 'webm' || fileExtension === 'webm') {
          console.warn('üí° WebM format detected - this is likely causing the decoding issue');
          console.warn('üí° Consider updating the frontend to record in WAV format instead');
          console.warn('üí° Or implement server-side format conversion');
        }
        
        // Return empty transcript instead of throwing error to prevent crashes
        return '';
      }
      
      throw fileError;
    }
    
  } catch (error) {
    console.error('‚ùå Error in Whisper STT processing:', error);
    
    // Enhanced error handling with suggestions
    if (error.status === 429) {
      console.warn('‚ö†Ô∏è OpenAI API rate limit reached - consider throttling requests');
    } else if (error.status === 401) {
      console.warn('‚ö†Ô∏è OpenAI API key invalid - check OPENAI_API_KEY environment variable');
    } else if (error.status === 400) {
      console.warn('‚ö†Ô∏è OpenAI Whisper rejected audio format:');
      console.warn('üìù Error details:', error.message);
      console.warn('üí° Suggestion: The audio format may be corrupted or unsupported');
      console.warn('üí° Try adjusting MediaRecorder settings in the frontend');
    } else if (error.code === 'ENOENT') {
      console.warn('‚ö†Ô∏è File system error - check temp directory permissions');
    }
    
    return '';
  }
}

// WebSocket endpoint for real-time audio streaming
wss.on('connection', (ws, req) => {
  console.log('üîó WebSocket client connected for audio streaming');
  
  let currentVoiceSession = null;
  let audioChunkBuffer = [];
  let processingTimer = null;
  
  ws.on('message', async (message) => {
    try {
      const data = JSON.parse(message);
      
      // Handle session association
      if (data.type === 'join_session' && data.sessionId) {
        currentVoiceSession = voiceSessions.get(data.sessionId);
        if (currentVoiceSession) {
          currentVoiceSession.setWebSocketConnection(ws);
          console.log(`üîó WebSocket joined voice session: ${data.sessionId}`);
          
          ws.send(JSON.stringify({
            type: 'session_joined',
            sessionId: data.sessionId,
            status: 'connected'
          }));
        } else {
          ws.send(JSON.stringify({
            type: 'error',
            message: 'Voice session not found'
          }));
        }
        return;
      }
      
      // Handle real-time audio chunks
      if (data.type === 'audio_chunk' && data.audioData) {
        // Since frontend now sends complete audio files, process immediately
        if (data.isCompleteFile) {
          try {
            console.log(`üéµ Received complete audio file (${data.format || 'unknown'} format)`);
            
            // Convert base64 to buffer
            const audioBuffer = Buffer.from(data.audioData, 'base64');
            
            if (audioBuffer.length < 1000) {
              console.log('üîá Audio file too small, skipping');
              return;
            }
            
            // Process with STT immediately since it's a complete file
            const transcript = await processAudioForSTT(audioBuffer, data.format || 'webm');
            
            if (transcript && transcript.trim().length > 0) {
              console.log(`üó£Ô∏è Real-time transcript: ${transcript}`);
              
              // Send transcription update
              ws.send(JSON.stringify({
                type: 'realtime_transcript',
                transcript,
                sessionId: currentVoiceSession?.sessionId,
                timestamp: new Date().toISOString()
              }));
              
              // Process with AI if it looks complete
              if (currentVoiceSession && (transcript.endsWith('.') || transcript.endsWith('!') || transcript.endsWith('?') || transcript.length > 10)) {
                await currentVoiceSession.processVoiceInput(transcript);
              }
            }
          } catch (error) {
            console.error('‚ùå Error processing complete audio file:', error);
            ws.send(JSON.stringify({
              type: 'error',
              message: 'Error processing audio',
              timestamp: new Date().toISOString()
            }));
          }
        } else {
          // Legacy support for chunk accumulation
          audioChunkBuffer.push({
            data: data.audioData,
            format: data.format || 'webm',
            mimeType: data.mimeType
          });
          
          // Clear existing timer
          if (processingTimer) {
            clearTimeout(processingTimer);
          }
          
          // Process after short delay (allows for interruption)
          processingTimer = setTimeout(async () => {
            if (audioChunkBuffer.length > 0) {
              await processRealTimeAudio(ws, currentVoiceSession);
            }
          }, 800); // 800ms delay for natural speech pauses
        }
        
        return;
      }
      
      // Handle interruption
      if (data.type === 'interrupt') {
        console.log('üõë Interruption received via WebSocket');
        
        // Clear audio buffer and processing timer
        audioChunkBuffer = [];
        if (processingTimer) {
          clearTimeout(processingTimer);
          processingTimer = null;
        }
        
        // Stop current session processing
        if (currentVoiceSession) {
          currentVoiceSession.isProcessing = false;
        }
        
        ws.send(JSON.stringify({
          type: 'interrupt_confirmed',
          timestamp: new Date().toISOString()
        }));
        
        return;
      }
      
      // Legacy support for existing audio processing
      if (data.type === 'audio' && data.data) {
        // Convert base64 audio data back to buffer
        const audioBuffer = Buffer.from(data.data, 'base64');
        
        console.log('üé§ Received audio chunk via WebSocket:', audioBuffer.length, 'bytes');
        
        // Process audio with Whisper STT
        const transcript = await processAudioForSTT(audioBuffer, 'wav');
        
        if (transcript && transcript.length > 0) {
          console.log('üó£Ô∏è WebSocket STT result:', transcript);
          
          // Send transcription back to client
          ws.send(JSON.stringify({
            type: 'transcription',
            text: transcript,
            timestamp: new Date().toISOString()
          }));
          
          // If this looks like a complete sentence, process it with AI
          if (transcript.endsWith('.') || transcript.endsWith('!') || transcript.endsWith('?') || transcript.length > 15) {
            console.log('ü§ñ Processing complete sentence with AI...');
            
            try {
              // Get AI response (simplified prompt for voice)
              const voicePrompt = `You are Finley, a helpful financial assistant. Give a brief, conversational response to: "${transcript}"
              
              Keep responses short and natural for voice conversation. If this is about finances, be helpful but concise.`;
              
              const response = await genAI.models.generateContent({
                model: 'gemini-2.5-flash-preview-05-20',
                contents: voicePrompt,
              });

              const aiText = response.text || "I'm here to help with your finances.";
              console.log('ü§ñ AI response:', aiText);

              // Convert AI response to speech if Cartesia is available
              if (process.env.CARTESIA_API_KEY) {
                try {
                  console.log('üîä Converting AI response to speech...');
                  const audioBuffer = await textToSpeech(aiText);
                  
                  // Send audio response back to client
                  const base64Audio = audioBuffer.toString('base64');
                  ws.send(JSON.stringify({
                    type: 'audio',
                    audioData: base64Audio,
                    text: aiText,
                    timestamp: new Date().toISOString()
                  }));
                  
                  console.log('‚úÖ Audio response sent via WebSocket');
                } catch (ttsError) {
                  console.error('‚ùå TTS Error:', ttsError);
                  // Send text-only response as fallback
                  ws.send(JSON.stringify({
                    type: 'text',
                    text: aiText,
                    timestamp: new Date().toISOString()
                  }));
                }
              } else {
                // Send text-only response if TTS not available
                ws.send(JSON.stringify({
                  type: 'text',
                  text: aiText,
                  timestamp: new Date().toISOString()
                }));
              }
              
            } catch (aiError) {
              console.error('‚ùå AI Processing Error:', aiError);
              ws.send(JSON.stringify({
                type: 'error',
                message: 'Sorry, I had trouble processing that.',
                timestamp: new Date().toISOString()
              }));
            }
          }
        }
      }
      
    } catch (error) {
      console.error('‚ùå WebSocket message processing error:', error);
      ws.send(JSON.stringify({
        type: 'error',
        message: 'Error processing audio',
        timestamp: new Date().toISOString()
      }));
    }
  });
  
  // Process buffered real-time audio
  async function processRealTimeAudio(ws, session) {
    if (!session || audioChunkBuffer.length === 0) {
      return;
    }
    
    try {
      // Get format from the first chunk (they should all be the same)
      let audioFormat = 'webm'; // Default to webm as that's what MediaRecorder typically uses
      
      // If we have metadata about format, use it
      if (audioChunkBuffer.length > 0 && typeof audioChunkBuffer[0] === 'object') {
        audioFormat = audioChunkBuffer[0].format || 'webm';
        // Combine just the audio data
        const combinedAudio = audioChunkBuffer.map(chunk => chunk.data).join('');
        audioChunkBuffer = []; // Clear buffer
        
        // Convert to buffer
        const audioBuffer = Buffer.from(combinedAudio, 'base64');
        
        if (audioBuffer.length < 5000) {
          // Skip very small audio chunks - need substantial audio for good transcription
          console.log(`üîá Skipping small audio chunk: ${audioBuffer.length} bytes`);
          return;
        }
        
        console.log(`üé§ Processing ${audioBuffer.length} bytes for session ${session.sessionId} (format: ${audioFormat})`);
        
        // Process with STT using the correct format
        const transcript = await processAudioForSTT(audioBuffer, audioFormat);
        
        if (transcript && transcript.trim().length > 0) {
          console.log(`üó£Ô∏è Real-time transcript: ${transcript}`);
          
          // Send transcription update
          ws.send(JSON.stringify({
            type: 'realtime_transcript',
            transcript,
            sessionId: session.sessionId,
            timestamp: new Date().toISOString()
          }));
          
          // Use debounced processing instead of immediate processing
          session.debouncedProcessSpeech(transcript);
        }
      } else {
        // Legacy mode - just audio data strings
        const combinedAudio = audioChunkBuffer.join('');
        audioChunkBuffer = []; // Clear buffer
        
        // Convert to buffer
        const audioBuffer = Buffer.from(combinedAudio, 'base64');
        
        if (audioBuffer.length < 5000) {
          // Skip very small audio chunks - need substantial audio for good transcription
          console.log(`üîá Skipping small audio chunk: ${audioBuffer.length} bytes`);
          return;
        }
        
        console.log(`üé§ Processing ${audioBuffer.length} bytes for session ${session.sessionId}`);
        
        // Process with STT - try to detect format from buffer
        const transcript = await processAudioForSTT(audioBuffer, 'webm');
        
        if (transcript && transcript.trim().length > 0) {
          console.log(`üó£Ô∏è Real-time transcript: ${transcript}`);
          
          // Send transcription update
          ws.send(JSON.stringify({
            type: 'realtime_transcript',
            transcript,
            sessionId: session.sessionId,
            timestamp: new Date().toISOString()
          }));
          
          // Use debounced processing instead of immediate processing
          session.debouncedProcessSpeech(transcript);
        }
      }
      
    } catch (error) {
      console.error('‚ùå Real-time audio processing error:', error);
      ws.send(JSON.stringify({
        type: 'error',
        message: 'Error processing real-time audio',
        timestamp: new Date().toISOString()
      }));
    }
  }
  
  ws.on('close', () => {
    console.log('üì° WebSocket client disconnected');
    
    // Clean up timers
    if (processingTimer) {
      clearTimeout(processingTimer);
    }
    
    // Disconnect from voice session
    if (currentVoiceSession) {
      currentVoiceSession.wsConnection = null;
    }
  });
  
  ws.on('error', (error) => {
    console.error('‚ùå WebSocket error:', error);
  });
});

// Removed duplicate server.listen() call - only using the one at the bottom

// Real-time voice chat endpoints

// Start a new real-time voice session
app.post('/api/voice/realtime/start', async (req, res) => {
  try {
    const { userId, accessToken } = req.body;
    const sessionId = `voice_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    
    // Create new voice session with access token for financial context
    const voiceSession = new RealTimeVoiceSession(sessionId, userId, accessToken);
    const sessionData = await voiceSession.initialize();
    
    // Store session
    voiceSessions.set(sessionId, voiceSession);
    
    console.log(`‚úÖ Started real-time voice session: ${sessionId}`);
    
    res.json({
      success: true,
      sessionId,
      dailyRoom: sessionData.dailyRoom,
      config: {
        hasDaily: !!process.env.DAILY_API_KEY,
        hasCartesia: !!process.env.CARTESIA_API_KEY,
        hasOpenAI: !!process.env.OPENAI_API_KEY,
        supportsInterruption: true,
        audioFormat: 'wav',
        sampleRate: 16000
      }
    });

  } catch (error) {
    console.error('‚ùå Failed to start real-time voice session:', error);
    res.status(500).json({ 
      success: false, 
      error: error.message 
    });
  }
});

// Stop a real-time voice session
app.post('/api/voice/realtime/stop', async (req, res) => {
  try {
    const { sessionId } = req.body;
    
    const session = voiceSessions.get(sessionId);
    if (!session) {
      return res.status(404).json({ 
        success: false, 
        error: 'Session not found' 
      });
    }
    
    await session.destroy();
    voiceSessions.delete(sessionId);
    
    console.log(`‚úÖ Stopped real-time voice session: ${sessionId}`);
    
    res.json({ 
      success: true, 
      sessionId,
      status: 'stopped' 
    });

  } catch (error) {
    console.error('‚ùå Failed to stop real-time voice session:', error);
    res.status(500).json({ 
      success: false, 
      error: error.message 
    });
  }
});

// Get active voice sessions
app.get('/api/voice/realtime/sessions', (req, res) => {
  const sessions = Array.from(voiceSessions.entries()).map(([id, session]) => ({
    sessionId: id,
    userId: session.userId,
    isActive: session.isActive,
    isProcessing: session.isProcessing,
    hasDaily: !!session.dailyRoom,
    conversationLength: session.conversationHistory.length
  }));

  res.json({ 
    success: true, 
    sessions,
    totalActive: sessions.filter(s => s.isActive).length
  });
});

// Process interruption
app.post('/api/voice/realtime/interrupt', async (req, res) => {
  try {
    const { sessionId } = req.body;
    
    const session = voiceSessions.get(sessionId);
    if (!session) {
      return res.status(404).json({ 
        success: false, 
        error: 'Session not found' 
      });
    }
    
    // Stop current processing and clear audio buffer
    session.isProcessing = false;
    session.audioChunkBuffer = [];
    
    // Send interruption signal via WebSocket
    if (session.wsConnection && session.wsConnection.readyState === 1) {
      session.wsConnection.send(JSON.stringify({
        type: 'interrupt',
        sessionId,
        timestamp: new Date().toISOString()
      }));
    }
    
    console.log(`üõë Interruption processed for session ${sessionId}`);
    
    res.json({ 
      success: true, 
      sessionId,
      status: 'interrupted' 
    });

  } catch (error) {
    console.error('‚ùå Failed to process interruption:', error);
    res.status(500).json({ 
      success: false, 
      error: error.message 
    });
  }
});

// For Vercel deployment, export the app
if (process.env.VERCEL) {
  module.exports = app;
} else {
  // For local development, start the server
  const PORT = process.env.PORT || 3001;
  server.listen(PORT, () => {
    console.log(`Server is running on port ${PORT}`);
    console.log(`Health check: http://localhost:${PORT}/api/health`);
    console.log('Environment variables check:');
    console.log('- GOOGLE_AI_API_KEY:', process.env.GOOGLE_AI_API_KEY ? 'Set' : 'Not set');
    console.log('- PLAID_CLIENT_ID:', process.env.PLAID_CLIENT_ID ? 'Set' : 'Not set');
    console.log('- PLAID_SECRET:', process.env.PLAID_SECRET ? 'Set' : 'Not set');
    console.log('- PLAID_ENV:', process.env.PLAID_ENV || 'Not set');
    console.log('- CARTESIA_API_KEY:', process.env.CARTESIA_API_KEY ? 'Set (Voice chat enabled)' : 'Not set (Voice chat disabled)');
    console.log('- DAILY_API_KEY:', process.env.DAILY_API_KEY ? 'Set (Daily.co enabled)' : 'Not set (Daily.co disabled)');
    console.log('- OPENAI_API_KEY:', process.env.OPENAI_API_KEY ? 'Set (Whisper STT enabled)' : 'Not set (Whisper STT disabled)');
  });
}